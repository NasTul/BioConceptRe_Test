{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.sax\n",
    "from xml.dom.minidom import parse\n",
    "import xml.dom.minidom\n",
    "import re\n",
    "from nltk.tokenize.punkt import PunktSentenceTokenizer, PunktParameters\n",
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "nlp=StanfordCoreNLP('G:\\\\stanford-corenlp-full-2018-10-05',lang='en')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data file\n",
    "def load_strtonum_feed(filename):\n",
    "    data = []\n",
    "    data_str = ''\n",
    "    with open(filename, 'r', encoding='UTF-8') as f:#with auto call close()\n",
    "        line = f.readline()\n",
    "        while line:\n",
    "            #read_data = line.split('\\n')\n",
    "            #data_str +=read_data\n",
    "            data_str +=line\n",
    "            #data.append(read_data[0])\n",
    "            line = f.readline()\n",
    "        return data_str "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "craft_ids_dev = load_strtonum_feed(\"craft-ids-dev.txt\").split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "craft_ids_train = load_strtonum_feed(\"craft-ids-train.txt\").split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "craft_ids_test = load_strtonum_feed(\"craft-ids-test.txt\").split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load file\n",
    "def txt_strtonum_feed(filename):\n",
    "    data = []\n",
    "    data_str = ''\n",
    "    with open(filename, 'r', encoding='UTF-8') as f:#with auto call close()\n",
    "        line = f.readline()\n",
    "        while line:\n",
    "            #read_data = line.split('\\n')\n",
    "            #data_str +=read_data\n",
    "            data_str +=line\n",
    "            #data.append(read_data[0])\n",
    "            line = f.readline()\n",
    "        return data_str "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_data(filename,ann_filename):\n",
    "        \n",
    "    txt = txt_strtonum_feed(filename)\n",
    "    DOMTree = xml.dom.minidom.parse(ann_filename)\n",
    "    collection = DOMTree.documentElement\n",
    "    annotations = collection.getElementsByTagName(\"annotation\")\n",
    "    data_list = []\n",
    "    for annotation in annotations:\n",
    "        mention = annotation.getElementsByTagName('class')[0].getAttribute(\"id\")\n",
    "\n",
    "        for span in annotation.getElementsByTagName('span'):\n",
    "            end = int(span.getAttribute(\"end\")  )   \n",
    "            start =int(span.getAttribute(\"start\")) \n",
    "            data = span.childNodes[0].data\n",
    "            data_list.append((start,end,mention,data))\n",
    "    data_list.sort()\n",
    "    \n",
    "    \n",
    "    # 获取开始的list\n",
    "    spanStart_list=[]\n",
    "    spanEnd_list=[]\n",
    "    # 获取文本\n",
    "    spannedText_list=[]\n",
    "    pr_list=[]\n",
    "    for i in data_list:\n",
    "        spanStart_list.append(i[0])\n",
    "        spanEnd_list.append(i[1])\n",
    "        spannedText_list.append(i[3])\n",
    "        pr_list.append(i[2])\n",
    "        \n",
    "        \n",
    "    punkt_param = PunktParameters()\n",
    "    abbreviation = ['i.e']\n",
    "    punkt_param.abbrev_types = set(abbreviation)\n",
    "    sent_tokenizer = PunktSentenceTokenizer(punkt_param)\n",
    "    \n",
    "    sentence_list =[]\n",
    "    data = re.split(\"\\n\\n\",txt)\n",
    "    for i in data:\n",
    "        sentence_list = sentence_list + sent_tokenizer.tokenize(i)\n",
    "    data = sentence_list\n",
    "    \n",
    "    #####################################3\n",
    "    #处理文本  new_tag_list ==\n",
    "    \"\"\"\n",
    "    [[('ocular', 'UBERON:0000970', 5, 11),\n",
    "    ('genetically', 'SO:0000704', 24, 35),\n",
    "    ('mice', 'NCBITaxon:10088', 45, 49)],\n",
    "    [],\n",
    "    \"\"\"\n",
    "    sentence_list = []\n",
    "    j = 0\n",
    "    number = 0\n",
    "    last_number = 0\n",
    "    new_tag_list = []\n",
    "    sub_tag_list = []\n",
    "    for i in range(len(data)):\n",
    "        number_ = txt[last_number:].find(data[i]) + last_number\n",
    "        \n",
    "        last_number= number_ + len(data[i])\n",
    "        \n",
    "        \n",
    "        while (j < len(spanEnd_list)) and  (spanEnd_list[j] <= last_number) and (spanEnd_list[j] >= number_):\n",
    "            sub_tag_list.append((spannedText_list[j],pr_list[j],int(spanStart_list[j])-number_ ,int(spanEnd_list[j])-number_))\n",
    "            j+=1\n",
    "        new_tag_list.append(sub_tag_list)\n",
    "        sub_tag_list=[]\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    #######################################\n",
    "    #先将文本处理成对应位置 doc_out_put===\n",
    "    \"\"\"\n",
    "    [[('Intraocular', 'JJ', 0, 11),\n",
    "      ('pressure', 'NN', 12, 20),\n",
    "      ('in', 'IN', 21, 23),\n",
    "      ('genetically', 'RB', 24, 35),\n",
    "      ('distinct', 'JJ', 36, 44),\n",
    "      ('mice', 'NNS', 45, 49),\n",
    "      (':', ':', 49, 50),\n",
    "      ('an', 'DT', 51, 53),\n",
    "      ('update', 'VB', 54, 60),\n",
    "      ('and', 'CC', 61, 64),\n",
    "      ('strain', 'VB', 65, 71),\n",
    "      ('survey', 'NN', 72, 78)],\n",
    "     [('Abstract', 'JJ', 0, 8)],\n",
    "    \"\"\"\n",
    "    doc_out_put = []\n",
    "    error_list = []\n",
    "    mark_list = ['(']\n",
    "    for i in range(len(data)):\n",
    "        sub_output = []\n",
    "        doc = nlp.pos_tag(data[i])\n",
    "        index_start = 0\n",
    "        index_end = 0\n",
    "\n",
    "        \n",
    "        for j in range(len(doc)):\n",
    "            index_start = data[i][index_end:].find(doc[j][0]) + index_end\n",
    "            index_end = index_start + len(doc[j][0])\n",
    "            sub_output.append((doc[j][0],doc[j][1],index_start,index_end))              \n",
    "        doc_out_put.append(sub_output)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #######################################\n",
    "    # 标注数据\n",
    "    store_data = []\n",
    "    for i in range(len(doc_out_put)):\n",
    "        sub_store_data = []\n",
    "        index_ = 0\n",
    "        for j in doc_out_put[i]:\n",
    "            label = 'O'\n",
    "            if  new_tag_list[i]:\n",
    "\n",
    "                #如果文本 比 标注的长， 那么让标注 滑动\n",
    "                while j[2] <= new_tag_list[i][index_][2] and j[3] >= new_tag_list[i][index_][3]:\n",
    "                        label = \"B\"\n",
    "#                         label = new_tag_list[i][index_][1]\n",
    "                        if index_ < len(new_tag_list[i])-1:\n",
    "                            index_+=1\n",
    "                        else:\n",
    "                            break\n",
    "                #如果文本比 标注短， 让文本滑动\n",
    "                if j[2] == new_tag_list[i][index_][2] and j[3] < new_tag_list[i][index_][3]:\n",
    "#                     label = new_tag_list[i][index_][1]\n",
    "                    label = \"B\"\n",
    "                elif j[2] > new_tag_list[i][index_][2] and j[3] < new_tag_list[i][index_][3]:\n",
    "#                     label = new_tag_list[i][index_][1]\n",
    "                    label = \"B\"\n",
    "                elif j[2] > new_tag_list[i][index_][2] and j[3] == new_tag_list[i][index_][3]:\n",
    "#                     label = new_tag_list[i][index_][1]\n",
    "                    label = \"B\"\n",
    "                    if index_ < len(new_tag_list[i])-1:\n",
    "                        index_+=1    \n",
    "\n",
    "\n",
    "            sub_store_data.append((j[0],j[1],label))\n",
    "        store_data.append(sub_store_data) \n",
    "        \n",
    "        \n",
    "    return store_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_data_train = []\n",
    "for i in craft_ids_train:\n",
    "    filename = \"data/\"+i+\".txt\"\n",
    "    ann_filename = \"data/\"+i+\".xml\"\n",
    "    store_data_train += handle_data(filename,ann_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_data_dev = []\n",
    "for i in craft_ids_dev:\n",
    "    filename = \"data/\"+i+\".txt\"\n",
    "    ann_filename = \"data/\"+i+\".xml\"\n",
    "    store_data_dev += handle_data(filename,ann_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_data_test = []\n",
    "for i in craft_ids_test:\n",
    "    filename = \"data/\"+i+\".txt\"\n",
    "    ann_filename = \"data/\"+i+\".xml\"\n",
    "    store_data_test += handle_data(filename,ann_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "fw = open('craft_ids_train.pl','wb')\n",
    "# Pickle the list using the highest protocol available.\n",
    "#pickle.dump(dataList, fw, -1)\n",
    "# Pickle dictionary using protocol 0.\n",
    "pickle.dump(store_data_train, fw)\n",
    "fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw = open('craft_ids_dev.pl','wb')\n",
    "# Pickle the list using the highest protocol available.\n",
    "#pickle.dump(dataList, fw, -1)\n",
    "# Pickle dictionary using protocol 0.\n",
    "pickle.dump(store_data_dev, fw)\n",
    "fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw = open('craft_ids_test.pl','wb')\n",
    "# Pickle the list using the highest protocol available.\n",
    "#pickle.dump(dataList, fw, -1)\n",
    "# Pickle dictionary using protocol 0.\n",
    "pickle.dump(store_data_test, fw)\n",
    "fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "fw = open('craft_ids_train_detail.pl','wb')\n",
    "# Pickle the list using the highest protocol available.\n",
    "#pickle.dump(dataList, fw, -1)\n",
    "# Pickle dictionary using protocol 0.\n",
    "pickle.dump(store_data_train, fw)\n",
    "fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw = open('craft_ids_dev_detail.pl','wb')\n",
    "# Pickle the list using the highest protocol available.\n",
    "#pickle.dump(dataList, fw, -1)\n",
    "# Pickle dictionary using protocol 0.\n",
    "pickle.dump(store_data_dev, fw)\n",
    "fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw = open('craft_ids_test_detail.pl','wb')\n",
    "# Pickle the list using the highest protocol available.\n",
    "#pickle.dump(dataList, fw, -1)\n",
    "# Pickle dictionary using protocol 0.\n",
    "pickle.dump(store_data_test, fw)\n",
    "fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "fr1 = open('craft_ids_train_detail.pl','rb')\n",
    "\n",
    "fr2 = open('craft_ids_dev_detail.pl','rb')\n",
    "\n",
    "fr3 = open('craft_ids_test_detail.pl','rb')\n",
    "\n",
    "store_data_train = pickle.load(fr1)\n",
    "store_data_dev = pickle.load(fr2)\n",
    "store_data_test = pickle.load(fr3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "fr1 = open('craft_ids_train.pl','rb')\n",
    "\n",
    "fr2 = open('craft_ids_dev.pl','rb')\n",
    "\n",
    "fr3 = open('craft_ids_test.pl','rb')\n",
    "\n",
    "store_data_train = pickle.load(fr1)\n",
    "store_data_dev = pickle.load(fr2)\n",
    "store_data_test = pickle.load(fr3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "lemmatizer = nltk.stem.wordnet.WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_data_trainx=[]\n",
    "store_data_trainy=[]\n",
    "for i in store_data_train:\n",
    "    sub_trainx = []\n",
    "    sub_trainy = []\n",
    "    for j in i:\n",
    "        word = lemmatizer.lemmatize(j[0])\n",
    "        sub_trainx.append(word)\n",
    "        sub_trainy.append(j[2])\n",
    "    store_data_trainx.append(sub_trainx)\n",
    "    store_data_trainy.append(sub_trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_data_devx=[]\n",
    "store_data_devy=[]\n",
    "for i in store_data_dev:\n",
    "    sub_trainx = []\n",
    "    sub_trainy = []\n",
    "    for j in i:\n",
    "        word = lemmatizer.lemmatize(j[0])\n",
    "        sub_trainx.append(word)\n",
    "        sub_trainy.append(j[2])\n",
    "    store_data_devx.append(sub_trainx)\n",
    "    store_data_devy.append(sub_trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_data_testx=[]\n",
    "store_data_testy=[]\n",
    "for i in store_data_test:\n",
    "    sub_trainx = []\n",
    "    sub_trainy = []\n",
    "    for j in i:\n",
    "        word = lemmatizer.lemmatize(j[0])\n",
    "        sub_trainx.append(word)\n",
    "        sub_trainy.append(j[2])\n",
    "    store_data_testx.append(sub_trainx)\n",
    "    store_data_testy.append(sub_trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## normal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_data_trainx=[]\n",
    "store_data_trainy=[]\n",
    "for i in store_data_train:\n",
    "    sub_trainx = []\n",
    "    sub_trainy = []\n",
    "    for j in i:\n",
    "        word = j[0]+j[1]\n",
    "#         sub_trainx.append(word)\n",
    "        sub_trainx.append(j[0])\n",
    "        sub_trainy.append(j[2])\n",
    "    store_data_trainx.append(sub_trainx)\n",
    "    store_data_trainy.append(sub_trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_data_devx=[]\n",
    "store_data_devy=[]\n",
    "for i in store_data_dev:\n",
    "    sub_trainx = []\n",
    "    sub_trainy = []\n",
    "    for j in i:\n",
    "        word = j[0]+j[1]\n",
    "#         sub_trainx.append(word)\n",
    "        sub_trainx.append(j[0])\n",
    "        sub_trainy.append(j[2])\n",
    "    store_data_devx.append(sub_trainx)\n",
    "    store_data_devy.append(sub_trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_data_testx=[]\n",
    "store_data_testy=[]\n",
    "for i in store_data_test:\n",
    "    sub_trainx = []\n",
    "    sub_trainy = []\n",
    "    for j in i:\n",
    "        word = j[0]+j[1]\n",
    "#         sub_trainx.append(word)\n",
    "        sub_trainx.append(j[0])\n",
    "        sub_trainy.append(j[2])\n",
    "    store_data_testx.append(sub_trainx)\n",
    "    store_data_testy.append(sub_trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打开一个文件\n",
    "fo = open(\"store_data_trainx.txt\", \"w\",encoding='gb18030')\n",
    "for i, sub_data_i in enumerate(store_data_trainx):\n",
    "    for j,sub_data_j  in enumerate(sub_data_i):\n",
    "        string = sub_data_j+\"\\t\"+store_data_trainy[i][j]+\"\\n\"\n",
    "        fo.write(string)\n",
    "    fo.write(\"\\n\")\n",
    "        \n",
    "# 关闭打开的文件\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打开一个文件\n",
    "fo = open(\"train_dev.tsv\", \"w\",encoding='gb18030')\n",
    "for i, sub_data_i in enumerate(store_data_devx):\n",
    "    for j,sub_data_j  in enumerate(sub_data_i):\n",
    "        string = sub_data_j+\"\\t\"+store_data_devy[i][j]+\"\\n\"\n",
    "        fo.write(string)\n",
    "    fo.write(\"\\n\")\n",
    "        \n",
    "# 关闭打开的文件\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打开一个文件\n",
    "fo = open(\"test.tsv\", \"w\",encoding='gb18030')\n",
    "for i, sub_data_i in enumerate(store_data_testx):\n",
    "    for j,sub_data_j  in enumerate(sub_data_i):\n",
    "        string = sub_data_j+\"\\t\"+store_data_testy[i][j]+\"\\n\"\n",
    "        fo.write(string)\n",
    "    fo.write(\"\\n\")\n",
    "        \n",
    "# 关闭打开的文件\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'O', 'O', 'O', 'O', 'B', 'B', 'O', 'O', 'B', 'B', 'O', 'O', 'B', 'O']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_data_testy[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split :   to  normalization ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_data_trainx=[]\n",
    "store_data_trainy=[]\n",
    "for i in store_data_train:\n",
    "    sub_trainx = []\n",
    "    sub_trainy = []\n",
    "    for j in i:\n",
    "#         word = j[2].split(\":\")[0]\n",
    "        sub_trainx.append(j[0])\n",
    "        sub_trainy.append(word)\n",
    "    store_data_trainx.append(sub_trainx)\n",
    "    store_data_trainy.append(sub_trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_data_devx=[]\n",
    "store_data_devy=[]\n",
    "for i in store_data_dev:\n",
    "    sub_trainx = []\n",
    "    sub_trainy = []\n",
    "    for j in i:\n",
    "#         word = j[2].split(\":\")[0]\n",
    "        sub_trainx.append(j[0])\n",
    "        sub_trainy.append(word)\n",
    "    store_data_devx.append(sub_trainx)\n",
    "    store_data_devy.append(sub_trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_data_testx=[]\n",
    "store_data_testy=[]\n",
    "for i in store_data_test:\n",
    "    sub_trainx = []\n",
    "    sub_trainy = []\n",
    "    for j in i:\n",
    "#         word = j[2].split(\":\")[0]\n",
    "        sub_trainx.append(j[0])\n",
    "        sub_trainy.append(word)\n",
    "    store_data_testx.append(sub_trainx)\n",
    "    store_data_testy.append(sub_trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:CUDA GPU available, you can set `kashgari.config.use_cudnn_cell = True` to use CuDNNCell. This will speed up the training, but will make model incompatible with CPU device.\n",
      "WARNING:root:CuDNN enabled, this will speed up the training, but will make model incompatible with CPU device.\n"
     ]
    }
   ],
   "source": [
    "import kashgari\n",
    "kashgari.config.use_cudnn_cell = True\n",
    "from kashgari.tasks.labeling import BiLSTM_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Sequence length will auto set at 95% of sequence length\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 50)]              0         \n",
      "_________________________________________________________________\n",
      "layer_embedding (Embedding)  (None, 50, 100)           1172900   \n",
      "_________________________________________________________________\n",
      "layer_blstm (Bidirectional)  (None, 50, 256)           235520    \n",
      "_________________________________________________________________\n",
      "layer_dropout (Dropout)      (None, 50, 256)           0         \n",
      "_________________________________________________________________\n",
      "layer_time_distributed (Time (None, 50, 3)             771       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 50, 3)             0         \n",
      "=================================================================\n",
      "Total params: 1,409,191\n",
      "Trainable params: 1,409,191\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "312/314 [============================>.] - ETA: 0s - loss: 0.1379 - acc: 0.9482Epoch 1/40\n",
      "314/314 [==============================] - 4s 13ms/step - loss: 0.1375 - acc: 0.9483 - val_loss: 0.0790 - val_acc: 0.9613\n",
      "Epoch 2/40\n",
      "312/314 [============================>.] - ETA: 0s - loss: 0.0376 - acc: 0.9864Epoch 1/40\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0377 - acc: 0.9864 - val_loss: 0.0785 - val_acc: 0.9636\n",
      "Epoch 3/40\n",
      "311/314 [============================>.] - ETA: 0s - loss: 0.0306 - acc: 0.9885Epoch 1/40\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0306 - acc: 0.9885 - val_loss: 0.0742 - val_acc: 0.9673\n",
      "Epoch 4/40\n",
      "313/314 [============================>.] - ETA: 0s - loss: 0.0252 - acc: 0.9904Epoch 1/40\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0252 - acc: 0.9904 - val_loss: 0.0896 - val_acc: 0.9652\n",
      "Epoch 5/40\n",
      "313/314 [============================>.] - ETA: 0s - loss: 0.0205 - acc: 0.9922Epoch 1/40\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0205 - acc: 0.9922 - val_loss: 0.0875 - val_acc: 0.9677\n",
      "Epoch 6/40\n",
      "309/314 [============================>.] - ETA: 0s - loss: 0.0171 - acc: 0.9936Epoch 1/40\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0172 - acc: 0.9936 - val_loss: 0.1004 - val_acc: 0.9666\n",
      "Epoch 7/40\n",
      "313/314 [============================>.] - ETA: 0s - loss: 0.0146 - acc: 0.9946Epoch 1/40\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0146 - acc: 0.9945 - val_loss: 0.1032 - val_acc: 0.9663\n",
      "Epoch 8/40\n",
      "307/314 [============================>.] - ETA: 0s - loss: 0.0123 - acc: 0.9954Epoch 1/40\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0123 - acc: 0.9954 - val_loss: 0.1139 - val_acc: 0.9664\n",
      "Epoch 9/40\n",
      "308/314 [============================>.] - ETA: 0s - loss: 0.0102 - acc: 0.9962Epoch 1/40\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0103 - acc: 0.9962 - val_loss: 0.1462 - val_acc: 0.9649\n",
      "Epoch 10/40\n",
      "310/314 [============================>.] - ETA: 0s - loss: 0.0090 - acc: 0.9967Epoch 1/40\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0090 - acc: 0.9967 - val_loss: 0.1363 - val_acc: 0.9667\n",
      "Epoch 11/40\n",
      "313/314 [============================>.] - ETA: 0s - loss: 0.0075 - acc: 0.9972Epoch 1/40\n",
      "314/314 [==============================] - 3s 10ms/step - loss: 0.0075 - acc: 0.9972 - val_loss: 0.1507 - val_acc: 0.9671\n",
      "Epoch 12/40\n",
      "308/314 [============================>.] - ETA: 0s - loss: 0.0064 - acc: 0.9976Epoch 1/40\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0064 - acc: 0.9976 - val_loss: 0.1630 - val_acc: 0.9654\n",
      "Epoch 13/40\n",
      "312/314 [============================>.] - ETA: 0s - loss: 0.0054 - acc: 0.9981Epoch 1/40\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0054 - acc: 0.9981 - val_loss: 0.1798 - val_acc: 0.9660\n",
      "Epoch 14/40\n",
      "309/314 [============================>.] - ETA: 0s - loss: 0.0045 - acc: 0.9984Epoch 1/40\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0045 - acc: 0.9984 - val_loss: 0.1870 - val_acc: 0.9660\n",
      "Epoch 15/40\n",
      "312/314 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.9986- ETA: 1s - lEpoch 1/40\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0039 - acc: 0.9986 - val_loss: 0.1886 - val_acc: 0.9662\n",
      "Epoch 16/40\n",
      "310/314 [============================>.] - ETA: 0s - loss: 0.0033 - acc: 0.9988Epoch 1/40\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0033 - acc: 0.9988 - val_loss: 0.2113 - val_acc: 0.9654\n",
      "Epoch 17/40\n",
      "312/314 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.9990Epoch 1/40\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0030 - acc: 0.9990 - val_loss: 0.2450 - val_acc: 0.9653\n",
      "Epoch 18/40\n",
      "309/314 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.9989Epoch 1/40\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0032 - acc: 0.9989 - val_loss: 0.2203 - val_acc: 0.9663\n",
      "Epoch 19/40\n",
      "313/314 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.9991Epoch 1/40\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0026 - acc: 0.9991 - val_loss: 0.2380 - val_acc: 0.9662\n",
      "Epoch 20/40\n",
      "308/314 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9993Epoch 1/40\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0021 - acc: 0.9993 - val_loss: 0.2600 - val_acc: 0.9657\n",
      "Epoch 21/40\n",
      "308/314 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9994Epoch 1/40\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0018 - acc: 0.9994 - val_loss: 0.2816 - val_acc: 0.9656\n",
      "Epoch 22/40\n",
      "311/314 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9994Epoch 1/40\n",
      "314/314 [==============================] - 3s 10ms/step - loss: 0.0018 - acc: 0.9994 - val_loss: 0.2645 - val_acc: 0.9657\n",
      "Epoch 23/40\n",
      "308/314 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9994Epoch 1/40\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0017 - acc: 0.9994 - val_loss: 0.2863 - val_acc: 0.9650\n",
      "Epoch 24/40\n",
      "309/314 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9995Epoch 1/40\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0016 - acc: 0.9995 - val_loss: 0.2719 - val_acc: 0.9651\n",
      "Epoch 25/40\n",
      "310/314 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9994Epoch 1/40\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0018 - acc: 0.9994 - val_loss: 0.2783 - val_acc: 0.9648\n",
      "Epoch 26/40\n",
      "311/314 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9995Epoch 1/40\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0013 - acc: 0.9995 - val_loss: 0.2780 - val_acc: 0.9657\n",
      "Epoch 27/40\n",
      "310/314 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9996Epoch 1/40\n",
      "314/314 [==============================] - 3s 10ms/step - loss: 0.0013 - acc: 0.9996 - val_loss: 0.2922 - val_acc: 0.9646\n",
      "Epoch 28/40\n",
      "309/314 [============================>.] - ETA: 0s - loss: 0.0011 - acc: 0.9996Epoch 1/40\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0011 - acc: 0.9996 - val_loss: 0.2986 - val_acc: 0.9649\n",
      "Epoch 29/40\n",
      "312/314 [============================>.] - ETA: 0s - loss: 9.9301e-04 - acc: 0.9997Epoch 1/40\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 9.9935e-04 - acc: 0.9997 - val_loss: 0.3096 - val_acc: 0.9653\n",
      "Epoch 30/40\n",
      "309/314 [============================>.] - ETA: 0s - loss: 9.3175e-04 - acc: 0.9997Epoch 1/40\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 9.3028e-04 - acc: 0.9997 - val_loss: 0.2836 - val_acc: 0.9667\n",
      "Epoch 31/40\n",
      "309/314 [============================>.] - ETA: 0s - loss: 0.0011 - acc: 0.9996Epoch 1/40\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0012 - acc: 0.9996 - val_loss: 0.2809 - val_acc: 0.9662\n",
      "Epoch 32/40\n",
      "309/314 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9996Epoch 1/40\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0013 - acc: 0.9996 - val_loss: 0.3044 - val_acc: 0.9650\n",
      "Epoch 33/40\n",
      "309/314 [============================>.] - ETA: 0s - loss: 9.0628e-04 - acc: 0.9997Epoch 1/40\n",
      "314/314 [==============================] - 3s 10ms/step - loss: 9.0081e-04 - acc: 0.9997 - val_loss: 0.2793 - val_acc: 0.9663\n",
      "Epoch 34/40\n",
      "310/314 [============================>.] - ETA: 0s - loss: 6.7776e-04 - acc: 0.9998Epoch 1/40\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 6.9573e-04 - acc: 0.9998 - val_loss: 0.3066 - val_acc: 0.9656\n",
      "Epoch 35/40\n",
      "310/314 [============================>.] - ETA: 0s - loss: 9.6517e-04 - acc: 0.9997Epoch 1/40\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 9.6667e-04 - acc: 0.9997 - val_loss: 0.3071 - val_acc: 0.9660\n",
      "Epoch 36/40\n",
      "312/314 [============================>.] - ETA: 0s - loss: 9.0025e-04 - acc: 0.9997Epoch 1/40\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 8.9670e-04 - acc: 0.9997 - val_loss: 0.3115 - val_acc: 0.9657\n",
      "Epoch 37/40\n",
      "308/314 [============================>.] - ETA: 0s - loss: 6.7142e-04 - acc: 0.9998Epoch 1/40\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 6.7054e-04 - acc: 0.9998 - val_loss: 0.3110 - val_acc: 0.9661\n",
      "Epoch 38/40\n",
      "313/314 [============================>.] - ETA: 0s - loss: 5.2523e-04 - acc: 0.9998Epoch 1/40\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 5.2408e-04 - acc: 0.9998 - val_loss: 0.3310 - val_acc: 0.9654\n",
      "Epoch 39/40\n",
      "313/314 [============================>.] - ETA: 0s - loss: 9.7041e-04 - acc: 0.9997Epoch 1/40\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 9.6762e-04 - acc: 0.9997 - val_loss: 0.3241 - val_acc: 0.9648\n",
      "Epoch 40/40\n",
      "309/314 [============================>.] - ETA: 0s - loss: 0.0010 - acc: 0.9997Epoch 1/40\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0010 - acc: 0.9997 - val_loss: 0.3067 - val_acc: 0.9657\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24183a779e8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BiLSTM_Model()\n",
    "#valid_x, valid_y = trainx[:250], trainy[:250]\n",
    "model.fit(store_data_trainx, store_data_trainy, store_data_devx, store_data_devy,epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           precision    recall  f1-score   support\n",
      "\n",
      "        B     0.8119    0.7171    0.7616     31293\n",
      "\n",
      "micro avg     0.8119    0.7171    0.7615     31293\n",
      "macro avg     0.8119    0.7171    0.7616     31293\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'           precision    recall  f1-score   support\\n\\n        B     0.8119    0.7171    0.7616     31293\\n\\nmicro avg     0.8119    0.7171    0.7615     31293\\nmacro avg     0.8119    0.7171    0.7616     31293\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 验证模型，此方法将打印出详细的验证报告\n",
    "model.evaluate(store_data_testx, store_data_testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "micro avg     0.8690    0.6592    0.7497     31293\n",
    "macro avg     0.8692    0.6592    0.7498     31293"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"BiLSTM10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['O', 'O', 'O', 'O', 'O', 'B', 'B', 'O', 'O', 'B', 'B', 'O', 'O', 'B', 'O']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([store_data_testx[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Complex',\n",
       " 'trait',\n",
       " 'analysis',\n",
       " 'of',\n",
       " 'the',\n",
       " 'mouse',\n",
       " 'striatum',\n",
       " ':',\n",
       " 'independent',\n",
       " 'QTLs',\n",
       " 'modulate',\n",
       " 'volume',\n",
       " 'and',\n",
       " 'neuron',\n",
       " 'number']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_data_testx[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Sequence length will auto set at 95% of sequence length\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 50)]              0         \n",
      "_________________________________________________________________\n",
      "layer_embedding (Embedding)  (None, 50, 100)           1101800   \n",
      "_________________________________________________________________\n",
      "layer_blstm (Bidirectional)  (None, 50, 256)           235520    \n",
      "_________________________________________________________________\n",
      "layer_dropout (Dropout)      (None, 50, 256)           0         \n",
      "_________________________________________________________________\n",
      "layer_time_distributed (Time (None, 50, 3)             771       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 50, 3)             0         \n",
      "=================================================================\n",
      "Total params: 1,338,091\n",
      "Trainable params: 1,338,091\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "311/314 [============================>.] - ETA: 0s - loss: 0.1385 - acc: 0.9499Epoch 1/50\n",
      "314/314 [==============================] - 4s 12ms/step - loss: 0.1375 - acc: 0.9502 - val_loss: 0.0817 - val_acc: 0.9619\n",
      "Epoch 2/50\n",
      "312/314 [============================>.] - ETA: 0s - loss: 0.0376 - acc: 0.9864Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0376 - acc: 0.9864 - val_loss: 0.0765 - val_acc: 0.9651\n",
      "Epoch 3/50\n",
      "308/314 [============================>.] - ETA: 0s - loss: 0.0306 - acc: 0.9887Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0306 - acc: 0.9886 - val_loss: 0.0723 - val_acc: 0.9678\n",
      "Epoch 4/50\n",
      "307/314 [============================>.] - ETA: 0s - loss: 0.0243 - acc: 0.9909Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0243 - acc: 0.9909 - val_loss: 0.0740 - val_acc: 0.9701\n",
      "Epoch 5/50\n",
      "307/314 [============================>.] - ETA: 0s - loss: 0.0198 - acc: 0.9926Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0198 - acc: 0.9926 - val_loss: 0.0857 - val_acc: 0.9687\n",
      "Epoch 6/50\n",
      "313/314 [============================>.] - ETA: 0s - loss: 0.0170 - acc: 0.9937Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0170 - acc: 0.9937 - val_loss: 0.1018 - val_acc: 0.9666\n",
      "Epoch 7/50\n",
      "307/314 [============================>.] - ETA: 0s - loss: 0.0146 - acc: 0.9945Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0146 - acc: 0.9945 - val_loss: 0.1093 - val_acc: 0.9666\n",
      "Epoch 8/50\n",
      "307/314 [============================>.] - ETA: 0s - loss: 0.0125 - acc: 0.9954Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0126 - acc: 0.9953 - val_loss: 0.1103 - val_acc: 0.9672\n",
      "Epoch 9/50\n",
      "308/314 [============================>.] - ETA: 0s - loss: 0.0112 - acc: 0.9959Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0111 - acc: 0.9959 - val_loss: 0.1134 - val_acc: 0.9680\n",
      "Epoch 10/50\n",
      "313/314 [============================>.] - ETA: 0s - loss: 0.0094 - acc: 0.9966Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0094 - acc: 0.9966 - val_loss: 0.1400 - val_acc: 0.9666\n",
      "Epoch 11/50\n",
      "311/314 [============================>.] - ETA: 0s - loss: 0.0082 - acc: 0.9970Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0082 - acc: 0.9970 - val_loss: 0.1414 - val_acc: 0.9668\n",
      "Epoch 12/50\n",
      "307/314 [============================>.] - ETA: 0s - loss: 0.0067 - acc: 0.9976Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0067 - acc: 0.9976 - val_loss: 0.1660 - val_acc: 0.9662\n",
      "Epoch 13/50\n",
      "310/314 [============================>.] - ETA: 0s - loss: 0.0053 - acc: 0.9981Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0053 - acc: 0.9981 - val_loss: 0.1606 - val_acc: 0.9680\n",
      "Epoch 14/50\n",
      "308/314 [============================>.] - ETA: 0s - loss: 0.0045 - acc: 0.9984Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0045 - acc: 0.9984 - val_loss: 0.2108 - val_acc: 0.9640\n",
      "Epoch 15/50\n",
      "309/314 [============================>.] - ETA: 0s - loss: 0.0044 - acc: 0.9985Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0044 - acc: 0.9984 - val_loss: 0.1724 - val_acc: 0.9688\n",
      "Epoch 16/50\n",
      "313/314 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.9988Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0036 - acc: 0.9987 - val_loss: 0.1923 - val_acc: 0.9669\n",
      "Epoch 17/50\n",
      "307/314 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.9990Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0030 - acc: 0.9990 - val_loss: 0.2324 - val_acc: 0.9660\n",
      "Epoch 18/50\n",
      "313/314 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.9991Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0027 - acc: 0.9991 - val_loss: 0.2330 - val_acc: 0.9662\n",
      "Epoch 19/50\n",
      "308/314 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9993Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0022 - acc: 0.9993 - val_loss: 0.2355 - val_acc: 0.9665\n",
      "Epoch 20/50\n",
      "307/314 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9992Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0024 - acc: 0.9992 - val_loss: 0.2404 - val_acc: 0.9658\n",
      "Epoch 21/50\n",
      "308/314 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.9990Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0029 - acc: 0.9990 - val_loss: 0.2175 - val_acc: 0.9670\n",
      "Epoch 22/50\n",
      "311/314 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9993Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0022 - acc: 0.9993 - val_loss: 0.2395 - val_acc: 0.9652\n",
      "Epoch 23/50\n",
      "310/314 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9995Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0015 - acc: 0.9995 - val_loss: 0.2508 - val_acc: 0.9670\n",
      "Epoch 24/50\n",
      "313/314 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 0.9996Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0012 - acc: 0.9996 - val_loss: 0.2721 - val_acc: 0.9669\n",
      "Epoch 25/50\n",
      "310/314 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9996Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0013 - acc: 0.9996 - val_loss: 0.2633 - val_acc: 0.9670\n",
      "Epoch 26/50\n",
      "308/314 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9996Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0013 - acc: 0.9996 - val_loss: 0.2681 - val_acc: 0.9668\n",
      "Epoch 27/50\n",
      "311/314 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 0.9996Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0012 - acc: 0.9996 - val_loss: 0.2793 - val_acc: 0.9672\n",
      "Epoch 28/50\n",
      "307/314 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9995Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0014 - acc: 0.9995 - val_loss: 0.2660 - val_acc: 0.9677\n",
      "Epoch 29/50\n",
      "308/314 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9995Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0016 - acc: 0.9995 - val_loss: 0.2801 - val_acc: 0.9659\n",
      "Epoch 30/50\n",
      "311/314 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9996Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0013 - acc: 0.9996 - val_loss: 0.2623 - val_acc: 0.9669\n",
      "Epoch 31/50\n",
      "311/314 [============================>.] - ETA: 0s - loss: 9.9715e-04 - acc: 0.9997Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0010 - acc: 0.9997 - val_loss: 0.2837 - val_acc: 0.9658\n",
      "Epoch 32/50\n",
      "311/314 [============================>.] - ETA: 0s - loss: 6.4397e-04 - acc: 0.9998Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 6.4764e-04 - acc: 0.9998 - val_loss: 0.2956 - val_acc: 0.9669\n",
      "Epoch 33/50\n",
      "312/314 [============================>.] - ETA: 0s - loss: 5.8505e-04 - acc: 0.9998Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 5.8175e-04 - acc: 0.9998 - val_loss: 0.2968 - val_acc: 0.9664\n",
      "Epoch 34/50\n",
      "307/314 [============================>.] - ETA: 0s - loss: 6.5279e-04 - acc: 0.9998Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 6.4592e-04 - acc: 0.9998 - val_loss: 0.3068 - val_acc: 0.9659\n",
      "Epoch 35/50\n",
      "307/314 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 0.9996Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0012 - acc: 0.9996 - val_loss: 0.2852 - val_acc: 0.9673\n",
      "Epoch 36/50\n",
      "310/314 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9995Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0017 - acc: 0.9995 - val_loss: 0.2725 - val_acc: 0.9667\n",
      "Epoch 37/50\n",
      "313/314 [============================>.] - ETA: 0s - loss: 0.0010 - acc: 0.9997Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0010 - acc: 0.9997 - val_loss: 0.2843 - val_acc: 0.9667\n",
      "Epoch 38/50\n",
      "308/314 [============================>.] - ETA: 0s - loss: 5.3387e-04 - acc: 0.9999Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 5.3637e-04 - acc: 0.9999 - val_loss: 0.2874 - val_acc: 0.9674\n",
      "Epoch 39/50\n",
      "307/314 [============================>.] - ETA: 0s - loss: 3.8470e-04 - acc: 0.9999Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 3.8424e-04 - acc: 0.9999 - val_loss: 0.3019 - val_acc: 0.9660\n",
      "Epoch 40/50\n",
      "307/314 [============================>.] - ETA: 0s - loss: 3.1694e-04 - acc: 0.9999Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 3.1521e-04 - acc: 0.9999 - val_loss: 0.3171 - val_acc: 0.9658\n",
      "Epoch 41/50\n",
      "312/314 [============================>.] - ETA: 0s - loss: 3.9590e-04 - acc: 0.9999Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 3.9521e-04 - acc: 0.9999 - val_loss: 0.3028 - val_acc: 0.9669\n",
      "Epoch 42/50\n",
      "311/314 [============================>.] - ETA: 0s - loss: 5.5791e-04 - acc: 0.9998Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 5.5937e-04 - acc: 0.9998 - val_loss: 0.3303 - val_acc: 0.9665\n",
      "Epoch 43/50\n",
      "313/314 [============================>.] - ETA: 0s - loss: 5.4879e-04 - acc: 0.9998Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 5.4745e-04 - acc: 0.9998 - val_loss: 0.3229 - val_acc: 0.9666\n",
      "Epoch 44/50\n",
      "310/314 [============================>.] - ETA: 0s - loss: 5.8726e-04 - acc: 0.9998Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 5.8414e-04 - acc: 0.9998 - val_loss: 0.3145 - val_acc: 0.9662\n",
      "Epoch 45/50\n",
      "308/314 [============================>.] - ETA: 0s - loss: 6.6106e-04 - acc: 0.9998Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 6.6534e-04 - acc: 0.9998 - val_loss: 0.2939 - val_acc: 0.9666\n",
      "Epoch 46/50\n",
      "313/314 [============================>.] - ETA: 0s - loss: 9.7888e-04 - acc: 0.9997Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 9.8434e-04 - acc: 0.9997 - val_loss: 0.3020 - val_acc: 0.9656\n",
      "Epoch 47/50\n",
      "312/314 [============================>.] - ETA: 0s - loss: 8.8780e-04 - acc: 0.9997Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 8.8399e-04 - acc: 0.9997 - val_loss: 0.2847 - val_acc: 0.9672\n",
      "Epoch 48/50\n",
      "312/314 [============================>.] - ETA: 0s - loss: 5.0927e-04 - acc: 0.9998Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 5.3467e-04 - acc: 0.9998 - val_loss: 0.2964 - val_acc: 0.9668\n",
      "Epoch 49/50\n",
      "313/314 [============================>.] - ETA: 0s - loss: 3.9389e-04 - acc: 0.9999Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 3.9290e-04 - acc: 0.9999 - val_loss: 0.2973 - val_acc: 0.9668\n",
      "Epoch 50/50\n",
      "307/314 [============================>.] - ETA: 0s - loss: 2.3648e-04 - acc: 0.9999Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 2.4817e-04 - acc: 0.9999 - val_loss: 0.3199 - val_acc: 0.9668\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27cd6056f28>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BiLSTM_Model()\n",
    "#valid_x, valid_y = trainx[:250], trainy[:250]\n",
    "model.fit(store_data_trainx, store_data_trainy, store_data_devx, store_data_devy,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           precision    recall  f1-score   support\n",
      "\n",
      "        B     0.8081    0.7272    0.7655     31293\n",
      "\n",
      "micro avg     0.8080    0.7272    0.7655     31293\n",
      "macro avg     0.8081    0.7272    0.7655     31293\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'           precision    recall  f1-score   support\\n\\n        B     0.8081    0.7272    0.7655     31293\\n\\nmicro avg     0.8080    0.7272    0.7655     31293\\nmacro avg     0.8081    0.7272    0.7655     31293\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 验证模型，此方法将打印出详细的验证报告\n",
    "model.evaluate(store_data_testx, store_data_testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Sequence length will auto set at 95% of sequence length\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 50)]              0         \n",
      "_________________________________________________________________\n",
      "layer_embedding (Embedding)  (None, 50, 100)           1101800   \n",
      "_________________________________________________________________\n",
      "layer_blstm (Bidirectional)  (None, 50, 256)           235520    \n",
      "_________________________________________________________________\n",
      "layer_dropout (Dropout)      (None, 50, 256)           0         \n",
      "_________________________________________________________________\n",
      "layer_time_distributed (Time (None, 50, 3)             771       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 50, 3)             0         \n",
      "=================================================================\n",
      "Total params: 1,338,091\n",
      "Trainable params: 1,338,091\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "308/314 [============================>.] - ETA: 0s - loss: 0.1375 - acc: 0.9472Epoch 1/100\n",
      "314/314 [==============================] - 4s 12ms/step - loss: 0.1356 - acc: 0.9478 - val_loss: 0.0815 - val_acc: 0.9621\n",
      "Epoch 2/100\n",
      "310/314 [============================>.] - ETA: 0s - loss: 0.0371 - acc: 0.9867Epoch 1/100\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0371 - acc: 0.9867 - val_loss: 0.0889 - val_acc: 0.9626\n",
      "Epoch 3/100\n",
      "310/314 [============================>.] - ETA: 0s - loss: 0.0299 - acc: 0.9888Epoch 1/100\n",
      "314/314 [==============================] - ETA: 1s - loss: 0.0841 - acc: 0.966 - 3s 9ms/step - loss: 0.0299 - acc: 0.9889 - val_loss: 0.0852 - val_acc: 0.9661\n",
      "Epoch 4/100\n",
      "307/314 [============================>.] - ETA: 0s - loss: 0.0237 - acc: 0.9911Epoch 1/100\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0237 - acc: 0.9911 - val_loss: 0.0900 - val_acc: 0.9663\n",
      "Epoch 5/100\n",
      "313/314 [============================>.] - ETA: 0s - loss: 0.0197 - acc: 0.9926Epoch 1/100\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0198 - acc: 0.9926 - val_loss: 0.1011 - val_acc: 0.9656\n",
      "Epoch 6/100\n",
      "311/314 [============================>.] - ETA: 0s - loss: 0.0169 - acc: 0.9937Epoch 1/100\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0169 - acc: 0.9937 - val_loss: 0.1112 - val_acc: 0.9664\n",
      "Epoch 7/100\n",
      "309/314 [============================>.] - ETA: 0s - loss: 0.0147 - acc: 0.9945Epoch 1/100\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0148 - acc: 0.9945 - val_loss: 0.0993 - val_acc: 0.9677\n",
      "Epoch 8/100\n",
      "308/314 [============================>.] - ETA: 0s - loss: 0.0127 - acc: 0.9952Epoch 1/100\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0128 - acc: 0.9952 - val_loss: 0.1140 - val_acc: 0.9669\n",
      "Epoch 9/100\n",
      "311/314 [============================>.] - ETA: 0s - loss: 0.0112 - acc: 0.9959Epoch 1/100\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0112 - acc: 0.9959 - val_loss: 0.1364 - val_acc: 0.9654\n",
      "Epoch 10/100\n",
      "307/314 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.9964Epoch 1/100\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0098 - acc: 0.9964 - val_loss: 0.1301 - val_acc: 0.9672\n",
      "Epoch 11/100\n",
      "308/314 [============================>.] - ETA: 0s - loss: 0.0084 - acc: 0.9969Epoch 1/100\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0084 - acc: 0.9969 - val_loss: 0.1530 - val_acc: 0.9660\n",
      "Epoch 12/100\n",
      "312/314 [============================>.] - ETA: 0s - loss: 0.0070 - acc: 0.9974Epoch 1/100\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0070 - acc: 0.9974 - val_loss: 0.1615 - val_acc: 0.9659\n",
      "Epoch 13/100\n",
      "309/314 [============================>.] - ETA: 0s - loss: 0.0063 - acc: 0.9978Epoch 1/100\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0063 - acc: 0.9977 - val_loss: 0.1871 - val_acc: 0.9656\n",
      "Epoch 14/100\n",
      "309/314 [============================>.] - ETA: 0s - loss: 0.0052 - acc: 0.9981Epoch 1/100\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0052 - acc: 0.9981 - val_loss: 0.1882 - val_acc: 0.9657\n",
      "Epoch 15/100\n",
      "309/314 [============================>.] - ETA: 0s - loss: 0.0046 - acc: 0.9983Epoch 1/100\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0046 - acc: 0.9983 - val_loss: 0.1753 - val_acc: 0.9676\n",
      "Epoch 16/100\n",
      "308/314 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 0.9986Epoch 1/100\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0040 - acc: 0.9986 - val_loss: 0.1960 - val_acc: 0.9666\n",
      "Epoch 17/100\n",
      "311/314 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.9988Epoch 1/100\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0036 - acc: 0.9988 - val_loss: 0.2087 - val_acc: 0.9661\n",
      "Epoch 18/100\n",
      "310/314 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.9989Epoch 1/100\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0030 - acc: 0.9989 - val_loss: 0.2209 - val_acc: 0.9670\n",
      "Epoch 19/100\n",
      "313/314 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.9992Epoch 1/100\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0025 - acc: 0.9992 - val_loss: 0.2283 - val_acc: 0.9666\n",
      "Epoch 20/100\n",
      "311/314 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.9991Epoch 1/100\n",
      "314/314 [==============================] - 3s 10ms/step - loss: 0.0027 - acc: 0.9991 - val_loss: 0.2304 - val_acc: 0.9655\n",
      "Epoch 21/100\n",
      "311/314 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9993Epoch 1/100\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0021 - acc: 0.9993 - val_loss: 0.2593 - val_acc: 0.9663\n",
      "Epoch 22/100\n",
      "313/314 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9994Epoch 1/100\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0018 - acc: 0.9994 - val_loss: 0.2586 - val_acc: 0.9661\n",
      "Epoch 23/100\n",
      "309/314 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9995Epoch 1/100\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0016 - acc: 0.9995 - val_loss: 0.2590 - val_acc: 0.9662\n",
      "Epoch 24/100\n",
      "310/314 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9995Epoch 1/100\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0016 - acc: 0.9995 - val_loss: 0.2572 - val_acc: 0.9658\n",
      "Epoch 25/100\n",
      "313/314 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9992Epoch 1/100\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0024 - acc: 0.9992 - val_loss: 0.2399 - val_acc: 0.9663\n",
      "Epoch 26/100\n",
      "310/314 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9994Epoch 1/100\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0018 - acc: 0.9994 - val_loss: 0.2572 - val_acc: 0.9661\n",
      "Epoch 27/100\n",
      "311/314 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9996Epoch 1/100\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0014 - acc: 0.9996 - val_loss: 0.2690 - val_acc: 0.9654\n",
      "Epoch 28/100\n",
      "311/314 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9996Epoch 1/100\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0014 - acc: 0.9996 - val_loss: 0.2683 - val_acc: 0.9671\n",
      "Epoch 29/100\n",
      "313/314 [============================>.] - ETA: 0s - loss: 9.6097e-04 - acc: 0.9997Epoch 1/100\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 9.6123e-04 - acc: 0.9997 - val_loss: 0.2897 - val_acc: 0.9661\n",
      "Epoch 30/100\n",
      "312/314 [============================>.] - ETA: 0s - loss: 7.8991e-04 - acc: 0.9997Epoch 1/100\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 7.8776e-04 - acc: 0.9997 - val_loss: 0.3044 - val_acc: 0.9657\n",
      "Epoch 31/100\n",
      "311/314 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9995Epoch 1/100\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0019 - acc: 0.9994 - val_loss: 0.2918 - val_acc: 0.9652\n",
      "Epoch 32/100\n",
      "312/314 [============================>.] - ETA: 0s - loss: 9.9659e-04 - acc: 0.9997Epoch 1/100\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 9.9531e-04 - acc: 0.9997 - val_loss: 0.2921 - val_acc: 0.9661\n",
      "Epoch 33/100\n",
      "311/314 [============================>.] - ETA: 0s - loss: 5.5449e-04 - acc: 0.9998Epoch 1/100\n",
      "314/314 [==============================] - 3s 10ms/step - loss: 5.5295e-04 - acc: 0.9998 - val_loss: 0.3057 - val_acc: 0.9659\n",
      "Epoch 34/100\n",
      "313/314 [============================>.] - ETA: 0s - loss: 5.5403e-04 - acc: 0.9998Epoch 1/100\n",
      "314/314 [==============================] - 6s 18ms/step - loss: 5.5240e-04 - acc: 0.9998 - val_loss: 0.3117 - val_acc: 0.9656\n",
      "Epoch 35/100\n",
      "313/314 [============================>.] - ETA: 0s - loss: 6.5029e-04 - acc: 0.9998Epoch 1/100\n",
      "314/314 [==============================] - 4s 13ms/step - loss: 6.5186e-04 - acc: 0.9998 - val_loss: 0.3208 - val_acc: 0.9659\n",
      "Epoch 36/100\n",
      "313/314 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 0.9996Epoch 1/100\n",
      "314/314 [==============================] - 4s 13ms/step - loss: 0.0012 - acc: 0.9996 - val_loss: 0.3124 - val_acc: 0.9653\n",
      "Epoch 37/100\n",
      "312/314 [============================>.] - ETA: 0s - loss: 9.7730e-04 - acc: 0.9997Epoch 1/100\n",
      "314/314 [==============================] - 4s 12ms/step - loss: 9.7613e-04 - acc: 0.9997 - val_loss: 0.3038 - val_acc: 0.9655\n",
      "Epoch 38/100\n",
      "313/314 [============================>.] - ETA: 0s - loss: 6.6114e-04 - acc: 0.9998Epoch 1/100\n",
      "314/314 [==============================] - 4s 13ms/step - loss: 6.5938e-04 - acc: 0.9998 - val_loss: 0.3151 - val_acc: 0.9660\n",
      "Epoch 39/100\n",
      "313/314 [============================>.] - ETA: 0s - loss: 5.9214e-04 - acc: 0.9998Epoch 1/100\n",
      "314/314 [==============================] - 4s 13ms/step - loss: 5.9036e-04 - acc: 0.9998 - val_loss: 0.3284 - val_acc: 0.9648\n",
      "Epoch 40/100\n",
      "312/314 [============================>.] - ETA: 0s - loss: 8.6444e-04 - acc: 0.9997Epoch 1/100\n",
      "314/314 [==============================] - 4s 13ms/step - loss: 8.6135e-04 - acc: 0.9997 - val_loss: 0.3169 - val_acc: 0.9659\n",
      "Epoch 41/100\n",
      "312/314 [============================>.] - ETA: 0s - loss: 8.0221e-04 - acc: 0.9997Epoch 1/100\n",
      "314/314 [==============================] - 4s 12ms/step - loss: 8.0033e-04 - acc: 0.9997 - val_loss: 0.3055 - val_acc: 0.9662\n",
      "Epoch 42/100\n",
      "310/314 [============================>.] - ETA: 0s - loss: 6.8320e-04 - acc: 0.9998Epoch 1/100\n",
      "314/314 [==============================] - 4s 12ms/step - loss: 6.7640e-04 - acc: 0.9998 - val_loss: 0.3220 - val_acc: 0.9658\n",
      "Epoch 43/100\n",
      "313/314 [============================>.] - ETA: 0s - loss: 4.7836e-04 - acc: 0.9999Epoch 1/100\n",
      "314/314 [==============================] - 4s 11ms/step - loss: 4.7725e-04 - acc: 0.9999 - val_loss: 0.3277 - val_acc: 0.9650\n",
      "Epoch 44/100\n",
      "311/314 [============================>.] - ETA: 0s - loss: 6.9900e-04 - acc: 0.9998Epoch 1/100\n",
      "314/314 [==============================] - 4s 12ms/step - loss: 7.0083e-04 - acc: 0.9998 - val_loss: 0.3032 - val_acc: 0.9660\n",
      "Epoch 45/100\n",
      "313/314 [============================>.] - ETA: 0s - loss: 6.7226e-04 - acc: 0.9998Epoch 1/100\n",
      "314/314 [==============================] - 4s 11ms/step - loss: 6.7028e-04 - acc: 0.9998 - val_loss: 0.3244 - val_acc: 0.9654\n",
      "Epoch 46/100\n",
      "312/314 [============================>.] - ETA: 0s - loss: 6.1702e-04 - acc: 0.9998Epoch 1/100\n",
      "314/314 [==============================] - 4s 12ms/step - loss: 6.1404e-04 - acc: 0.9998 - val_loss: 0.3323 - val_acc: 0.9658\n",
      "Epoch 47/100\n",
      "310/314 [============================>.] - ETA: 0s - loss: 4.4176e-04 - acc: 0.9999Epoch 1/100\n",
      "314/314 [==============================] - 4s 11ms/step - loss: 4.3939e-04 - acc: 0.9999 - val_loss: 0.3355 - val_acc: 0.9658\n",
      "Epoch 48/100\n",
      "311/314 [============================>.] - ETA: 0s - loss: 4.0650e-04 - acc: 0.9999Epoch 1/100\n",
      "314/314 [==============================] - 4s 12ms/step - loss: 4.0561e-04 - acc: 0.9999 - val_loss: 0.3445 - val_acc: 0.9654\n",
      "Epoch 49/100\n",
      "309/314 [============================>.] - ETA: 0s - loss: 3.2274e-04 - acc: 0.9999Epoch 1/100\n",
      "314/314 [==============================] - 4s 11ms/step - loss: 3.1987e-04 - acc: 0.9999 - val_loss: 0.3419 - val_acc: 0.9656\n",
      "Epoch 50/100\n",
      "313/314 [============================>.] - ETA: 0s - loss: 3.2842e-04 - acc: 0.9999Epoch 1/100\n",
      "314/314 [==============================] - 4s 11ms/step - loss: 3.2794e-04 - acc: 0.9999 - val_loss: 0.3349 - val_acc: 0.9658\n",
      "Epoch 51/100\n",
      "312/314 [============================>.] - ETA: 0s - loss: 6.6528e-04 - acc: 0.9998Epoch 1/100\n",
      "314/314 [==============================] - 4s 11ms/step - loss: 6.6457e-04 - acc: 0.9998 - val_loss: 0.3225 - val_acc: 0.9657\n",
      "Epoch 52/100\n",
      "309/314 [============================>.] - ETA: 0s - loss: 5.4530e-04 - acc: 0.9998Epoch 1/100\n",
      "314/314 [==============================] - 4s 11ms/step - loss: 5.4555e-04 - acc: 0.9998 - val_loss: 0.3056 - val_acc: 0.9667\n",
      "Epoch 53/100\n",
      "309/314 [============================>.] - ETA: 0s - loss: 4.8294e-04 - acc: 0.9998Epoch 1/100\n",
      "314/314 [==============================] - 4s 12ms/step - loss: 4.8972e-04 - acc: 0.9998 - val_loss: 0.3208 - val_acc: 0.9667\n",
      "Epoch 54/100\n",
      "310/314 [============================>.] - ETA: 0s - loss: 6.4643e-04 - acc: 0.9998Epoch 1/100\n",
      "314/314 [==============================] - 4s 12ms/step - loss: 6.4843e-04 - acc: 0.9998 - val_loss: 0.3229 - val_acc: 0.9659\n",
      "Epoch 55/100\n",
      "313/314 [============================>.] - ETA: 0s - loss: 5.4185e-04 - acc: 0.9998Epoch 1/100\n",
      "314/314 [==============================] - 4s 11ms/step - loss: 5.4027e-04 - acc: 0.9998 - val_loss: 0.3219 - val_acc: 0.9659\n",
      "Epoch 56/100\n",
      "311/314 [============================>.] - ETA: 0s - loss: 3.9057e-04 - acc: 0.9999Epoch 1/100\n",
      "314/314 [==============================] - 4s 11ms/step - loss: 3.8809e-04 - acc: 0.9999 - val_loss: 0.3470 - val_acc: 0.9652\n",
      "Epoch 57/100\n",
      "313/314 [============================>.] - ETA: 0s - loss: 6.1113e-04 - acc: 0.9998Epoch 1/100\n",
      "314/314 [==============================] - 4s 12ms/step - loss: 6.1115e-04 - acc: 0.9998 - val_loss: 0.3443 - val_acc: 0.9656\n",
      "Epoch 58/100\n",
      "311/314 [============================>.] - ETA: 0s - loss: 7.0159e-04 - acc: 0.9998Epoch 1/100\n",
      "314/314 [==============================] - 4s 11ms/step - loss: 7.0080e-04 - acc: 0.9998 - val_loss: 0.3096 - val_acc: 0.9673\n",
      "Epoch 59/100\n",
      "313/314 [============================>.] - ETA: 0s - loss: 3.3402e-04 - acc: 0.9999Epoch 1/100\n",
      "314/314 [==============================] - 4s 12ms/step - loss: 3.6252e-04 - acc: 0.9999 - val_loss: 0.3458 - val_acc: 0.9653\n",
      "Epoch 60/100\n",
      "311/314 [============================>.] - ETA: 0s - loss: 1.8781e-04 - acc: 1.0000Epoch 1/100\n",
      "314/314 [==============================] - 4s 12ms/step - loss: 1.8632e-04 - acc: 1.0000 - val_loss: 0.3231 - val_acc: 0.9675\n",
      "Epoch 61/100\n",
      "311/314 [============================>.] - ETA: 0s - loss: 1.4522e-04 - acc: 1.0000Epoch 1/100\n",
      "314/314 [==============================] - 4s 12ms/step - loss: 1.4553e-04 - acc: 1.0000 - val_loss: 0.3422 - val_acc: 0.9661\n",
      "Epoch 62/100\n",
      "312/314 [============================>.] - ETA: 0s - loss: 1.3694e-04 - acc: 1.0000Epoch 1/100\n",
      "314/314 [==============================] - 4s 11ms/step - loss: 1.3635e-04 - acc: 1.0000 - val_loss: 0.3619 - val_acc: 0.9655\n",
      "Epoch 63/100\n",
      "313/314 [============================>.] - ETA: 0s - loss: 2.1629e-04 - acc: 0.9999Epoch 1/100\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 2.1563e-04 - acc: 0.9999 - val_loss: 0.3566 - val_acc: 0.9657\n",
      "Epoch 64/100\n",
      "311/314 [============================>.] - ETA: 0s - loss: 3.8638e-04 - acc: 0.9999Epoch 1/100\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 3.8411e-04 - acc: 0.9999 - val_loss: 0.3433 - val_acc: 0.9658\n",
      "Epoch 65/100\n",
      "313/314 [============================>.] - ETA: 0s - loss: 4.0872e-04 - acc: 0.9999Epoch 1/100\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 4.1937e-04 - acc: 0.9999 - val_loss: 0.3489 - val_acc: 0.9658\n",
      "Epoch 66/100\n",
      "308/314 [============================>.] - ETA: 0s - loss: 5.7084e-04 - acc: 0.9998Epoch 1/100\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 5.8179e-04 - acc: 0.9998 - val_loss: 0.3451 - val_acc: 0.9658\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308/314 [============================>.] - ETA: 0s - loss: 7.0301e-04 - acc: 0.9998Epoch 1/100\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 6.9616e-04 - acc: 0.9998 - val_loss: 0.3107 - val_acc: 0.9674\n",
      "Epoch 68/100\n",
      "308/314 [============================>.] - ETA: 0s - loss: 4.2345e-04 - acc: 0.9999Epoch 1/100\n",
      "314/314 [==============================] - 3s 10ms/step - loss: 4.2218e-04 - acc: 0.9999 - val_loss: 0.3153 - val_acc: 0.9664\n",
      "Epoch 69/100\n",
      "308/314 [============================>.] - ETA: 0s - loss: 2.3554e-04 - acc: 0.9999- ETA: 0s - loss: 2.5832e-04 Epoch 1/100\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 2.5751e-04 - acc: 0.9999 - val_loss: 0.3441 - val_acc: 0.9654\n",
      "Epoch 70/100\n",
      "312/314 [============================>.] - ETA: 0s - loss: 1.7956e-04 - acc: 1.0000Epoch 1/100\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 1.7904e-04 - acc: 1.0000 - val_loss: 0.3439 - val_acc: 0.9657\n",
      "Epoch 71/100\n",
      "309/314 [============================>.] - ETA: 0s - loss: 2.0870e-04 - acc: 0.9999Epoch 1/100\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 2.0908e-04 - acc: 0.9999 - val_loss: 0.3448 - val_acc: 0.9652\n",
      "Epoch 72/100\n",
      "309/314 [============================>.] - ETA: 0s - loss: 3.6571e-04 - acc: 0.9999Epoch 1/100\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 3.7110e-04 - acc: 0.9999 - val_loss: 0.3449 - val_acc: 0.9661\n",
      "Epoch 73/100\n",
      "311/314 [============================>.] - ETA: 0s - loss: 2.8458e-04 - acc: 0.9999Epoch 1/100\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 2.8508e-04 - acc: 0.9999 - val_loss: 0.3357 - val_acc: 0.9661\n",
      "Epoch 74/100\n",
      "312/314 [============================>.] - ETA: 0s - loss: 1.8560e-04 - acc: 0.9999Epoch 1/100\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 1.8489e-04 - acc: 0.9999 - val_loss: 0.3476 - val_acc: 0.9664\n",
      "Epoch 75/100\n",
      "311/314 [============================>.] - ETA: 0s - loss: 1.3659e-04 - acc: 1.0000Epoch 1/100\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 1.3650e-04 - acc: 1.0000 - val_loss: 0.3504 - val_acc: 0.9657\n",
      "Epoch 76/100\n",
      "311/314 [============================>.] - ETA: 0s - loss: 2.5990e-04 - acc: 0.9999Epoch 1/100\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 2.6480e-04 - acc: 0.9999 - val_loss: 0.3400 - val_acc: 0.9660\n",
      "Epoch 77/100\n",
      "311/314 [============================>.] - ETA: 0s - loss: 3.8865e-04 - acc: 0.9999Epoch 1/100\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 3.8522e-04 - acc: 0.9999 - val_loss: 0.3439 - val_acc: 0.9656\n",
      "Epoch 78/100\n",
      "313/314 [============================>.] - ETA: 0s - loss: 4.8566e-04 - acc: 0.9999Epoch 1/100\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 4.8413e-04 - acc: 0.9999 - val_loss: 0.3315 - val_acc: 0.9661\n",
      "Epoch 79/100\n",
      "311/314 [============================>.] - ETA: 0s - loss: 3.3775e-04 - acc: 0.9999Epoch 1/100\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 3.3990e-04 - acc: 0.9999 - val_loss: 0.3315 - val_acc: 0.9664\n",
      "Epoch 80/100\n",
      "313/314 [============================>.] - ETA: 0s - loss: 2.2570e-04 - acc: 0.9999Epoch 1/100\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 2.2547e-04 - acc: 0.9999 - val_loss: 0.3527 - val_acc: 0.9658\n",
      "Epoch 81/100\n",
      "313/314 [============================>.] - ETA: 0s - loss: 1.7155e-04 - acc: 1.0000Epoch 1/100\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 1.7135e-04 - acc: 1.0000 - val_loss: 0.3484 - val_acc: 0.9662\n",
      "Epoch 82/100\n",
      "309/314 [============================>.] - ETA: 0s - loss: 2.3090e-04 - acc: 0.9999Epoch 1/100\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 2.2808e-04 - acc: 0.9999 - val_loss: 0.3567 - val_acc: 0.9647\n",
      "Epoch 83/100\n",
      "313/314 [============================>.] - ETA: 0s - loss: 4.9570e-04 - acc: 0.9999Epoch 1/100\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 4.9413e-04 - acc: 0.9999 - val_loss: 0.3411 - val_acc: 0.9662\n",
      "Epoch 84/100\n",
      "311/314 [============================>.] - ETA: 0s - loss: 2.9809e-04 - acc: 0.9999Epoch 1/100\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 2.9675e-04 - acc: 0.9999 - val_loss: 0.3596 - val_acc: 0.9648\n",
      "Epoch 85/100\n",
      "311/314 [============================>.] - ETA: 0s - loss: 2.2143e-04 - acc: 0.9999Epoch 1/100\n",
      "314/314 [==============================] - 4s 11ms/step - loss: 2.1946e-04 - acc: 0.9999 - val_loss: 0.3371 - val_acc: 0.9665\n",
      "Epoch 86/100\n",
      "311/314 [============================>.] - ETA: 0s - loss: 1.2871e-04 - acc: 1.0000Epoch 1/100\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 1.3471e-04 - acc: 1.0000 - val_loss: 0.3374 - val_acc: 0.9669\n",
      "Epoch 87/100\n",
      "313/314 [============================>.] - ETA: 0s - loss: 1.3720e-04 - acc: 1.0000Epoch 1/100\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 1.3677e-04 - acc: 1.0000 - val_loss: 0.3477 - val_acc: 0.9668\n",
      "Epoch 88/100\n",
      "311/314 [============================>.] - ETA: 0s - loss: 1.1040e-04 - acc: 1.0000Epoch 1/100\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 1.0943e-04 - acc: 1.0000 - val_loss: 0.3559 - val_acc: 0.9662\n",
      "Epoch 89/100\n",
      "311/314 [============================>.] - ETA: 0s - loss: 1.0660e-04 - acc: 1.0000Epoch 1/100\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 1.0578e-04 - acc: 1.0000 - val_loss: 0.3488 - val_acc: 0.9665\n",
      "Epoch 90/100\n",
      "312/314 [============================>.] - ETA: 0s - loss: 1.1334e-04 - acc: 1.0000Epoch 1/100\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 1.1271e-04 - acc: 1.0000 - val_loss: 0.3586 - val_acc: 0.9661\n",
      "Epoch 91/100\n",
      "313/314 [============================>.] - ETA: 0s - loss: 6.5749e-04 - acc: 0.9998Epoch 1/100\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 6.5781e-04 - acc: 0.9998 - val_loss: 0.3322 - val_acc: 0.9662\n",
      "Epoch 92/100\n",
      "311/314 [============================>.] - ETA: 0s - loss: 5.7477e-04 - acc: 0.9999Epoch 1/100\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 5.7145e-04 - acc: 0.9999 - val_loss: 0.3343 - val_acc: 0.9659\n",
      "Epoch 93/100\n",
      "309/314 [============================>.] - ETA: 0s - loss: 2.2183e-04 - acc: 0.9999Epoch 1/100\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 2.1999e-04 - acc: 0.9999 - val_loss: 0.3473 - val_acc: 0.9654\n",
      "Epoch 94/100\n",
      "312/314 [============================>.] - ETA: 0s - loss: 1.5349e-04 - acc: 1.0000Epoch 1/100\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 1.5273e-04 - acc: 1.0000 - val_loss: 0.3533 - val_acc: 0.9653\n",
      "Epoch 95/100\n",
      "312/314 [============================>.] - ETA: 0s - loss: 9.2140e-05 - acc: 1.0000Epoch 1/100\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 9.2043e-05 - acc: 1.0000 - val_loss: 0.3771 - val_acc: 0.9642\n",
      "Epoch 96/100\n",
      "311/314 [============================>.] - ETA: 0s - loss: 1.1697e-04 - acc: 1.0000Epoch 1/100\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 1.1660e-04 - acc: 1.0000 - val_loss: 0.3555 - val_acc: 0.9664\n",
      "Epoch 97/100\n",
      "309/314 [============================>.] - ETA: 0s - loss: 8.7526e-05 - acc: 1.0000Epoch 1/100\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 8.6822e-05 - acc: 1.0000 - val_loss: 0.3590 - val_acc: 0.9661\n",
      "Epoch 98/100\n",
      "312/314 [============================>.] - ETA: 0s - loss: 1.4015e-04 - acc: 1.0000Epoch 1/100\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 1.4103e-04 - acc: 1.0000 - val_loss: 0.3453 - val_acc: 0.9654\n",
      "Epoch 99/100\n",
      "309/314 [============================>.] - ETA: 0s - loss: 1.1176e-04 - acc: 1.0000Epoch 1/100\n",
      "314/314 [==============================] - 4s 12ms/step - loss: 1.1291e-04 - acc: 1.0000 - val_loss: 0.3619 - val_acc: 0.9661\n",
      "Epoch 100/100\n",
      "312/314 [============================>.] - ETA: 0s - loss: 1.7801e-04 - acc: 0.9999Epoch 1/100\n",
      "314/314 [==============================] - 3s 10ms/step - loss: 1.7932e-04 - acc: 0.9999 - val_loss: 0.3415 - val_acc: 0.9660\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27cf69715c0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BiLSTM_Model()\n",
    "#valid_x, valid_y = trainx[:250], trainy[:250]\n",
    "model.fit(store_data_trainx, store_data_trainy, store_data_devx, store_data_devy,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           precision    recall  f1-score   support\n",
      "\n",
      "        B     0.7998    0.7345    0.7658     31293\n",
      "\n",
      "micro avg     0.7998    0.7345    0.7658     31293\n",
      "macro avg     0.7998    0.7345    0.7658     31293\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'           precision    recall  f1-score   support\\n\\n        B     0.7998    0.7345    0.7658     31293\\n\\nmicro avg     0.7998    0.7345    0.7658     31293\\nmacro avg     0.7998    0.7345    0.7658     31293\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 验证模型，此方法将打印出详细的验证报告\n",
    "model.evaluate(store_data_testx, store_data_testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "micro avg     0.8084    0.7150    0.7588     31293\n",
    "macro avg     0.8088    0.7150    0.7590     31293\n",
    "\n",
    "micro avg     0.8080    0.7272    0.7655     31293\n",
    "macro avg     0.8081    0.7272    0.7655     31293\n",
    "\n",
    "\n",
    "micro avg     0.7998    0.7345    0.7658     31293\n",
    "macro avg     0.7998    0.7345    0.7658     31293\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10\n",
    "\n",
    "micro avg     0.7338    0.4433    0.5527     27140\n",
    "macro avg     0.4554    0.4433    0.4385     27140\n",
    "\n",
    "\n",
    "# 30\n",
    "micro avg     0.7192    0.5065    0.5944     27140\n",
    "macro avg     0.5328    0.5065    0.5094     27140\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 50 \n",
    " micro avg     0.6940    0.5132    0.5900     27140\n",
    "macro avg     0.5288    0.5132    0.5104     27140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#using \n",
    "#10\n",
    "           micro avg     0.7569    0.5656    0.6474     26737\n",
    "           macro avg     0.7240    0.5656    0.6186     26737\n",
    "\n",
    "        \n",
    "#30\n",
    "           micro avg     0.6966    0.5906    0.6392     26737\n",
    "           macro avg     0.6777    0.5906    0.6262     26737\n",
    "        \n",
    "\n",
    "\n",
    "#50 \n",
    "           micro avg     0.6947    0.6079    0.6484     26737\n",
    "           macro avg     0.6787    0.6079    0.6384     26737"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Sequence length will auto set at 95% of sequence length\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 50)]              0         \n",
      "_________________________________________________________________\n",
      "layer_embedding (Embedding)  (None, 50, 100)           1101800   \n",
      "_________________________________________________________________\n",
      "layer_blstm (Bidirectional)  (None, 50, 256)           235520    \n",
      "_________________________________________________________________\n",
      "layer_dropout (Dropout)      (None, 50, 256)           0         \n",
      "_________________________________________________________________\n",
      "layer_time_distributed (Time (None, 50, 3)             771       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 50, 3)             0         \n",
      "=================================================================\n",
      "Total params: 1,338,091\n",
      "Trainable params: 1,338,091\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "309/314 [============================>.] - ETA: 0s - loss: 0.1393 - acc: 0.9475Epoch 1/50\n",
      "314/314 [==============================] - 5s 17ms/step - loss: 0.1378 - acc: 0.9480 - val_loss: 0.0803 - val_acc: 0.9616\n",
      "Epoch 2/50\n",
      "310/314 [============================>.] - ETA: 0s - loss: 0.0371 - acc: 0.9865Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0371 - acc: 0.9865 - val_loss: 0.0915 - val_acc: 0.9621\n",
      "Epoch 3/50\n",
      "310/314 [============================>.] - ETA: 0s - loss: 0.0306 - acc: 0.9886-Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0306 - acc: 0.9886 - val_loss: 0.0970 - val_acc: 0.9636\n",
      "Epoch 4/50\n",
      "307/314 [============================>.] - ETA: 0s - loss: 0.0254 - acc: 0.9904- ETA: 1s - loss: 0Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0253 - acc: 0.9905 - val_loss: 0.0847 - val_acc: 0.9665\n",
      "Epoch 5/50\n",
      "310/314 [============================>.] - ETA: 0s - loss: 0.0210 - acc: 0.9921Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0210 - acc: 0.9921 - val_loss: 0.0924 - val_acc: 0.9670\n",
      "Epoch 6/50\n",
      "312/314 [============================>.] - ETA: 0s - loss: 0.0177 - acc: 0.9934Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0178 - acc: 0.9934 - val_loss: 0.1157 - val_acc: 0.9650\n",
      "Epoch 7/50\n",
      "312/314 [============================>.] - ETA: 0s - loss: 0.0153 - acc: 0.9943Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0152 - acc: 0.9943 - val_loss: 0.1048 - val_acc: 0.9666\n",
      "Epoch 8/50\n",
      "308/314 [============================>.] - ETA: 0s - loss: 0.0134 - acc: 0.9951Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0135 - acc: 0.9951 - val_loss: 0.1233 - val_acc: 0.9653\n",
      "Epoch 9/50\n",
      "309/314 [============================>.] - ETA: 0s - loss: 0.0114 - acc: 0.9958Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0114 - acc: 0.9958 - val_loss: 0.1319 - val_acc: 0.9657\n",
      "Epoch 10/50\n",
      "307/314 [============================>.] - ETA: 0s - loss: 0.0099 - acc: 0.9964Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0099 - acc: 0.9964 - val_loss: 0.1378 - val_acc: 0.9653\n",
      "Epoch 11/50\n",
      "312/314 [============================>.] - ETA: 0s - loss: 0.0084 - acc: 0.9969Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0085 - acc: 0.9969 - val_loss: 0.1523 - val_acc: 0.9668\n",
      "Epoch 12/50\n",
      "313/314 [============================>.] - ETA: 0s - loss: 0.0070 - acc: 0.9974Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0069 - acc: 0.9974 - val_loss: 0.1717 - val_acc: 0.9650\n",
      "Epoch 13/50\n",
      "312/314 [============================>.] - ETA: 0s - loss: 0.0062 - acc: 0.9977Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0062 - acc: 0.9977 - val_loss: 0.1714 - val_acc: 0.9665\n",
      "Epoch 14/50\n",
      "312/314 [============================>.] - ETA: 0s - loss: 0.0054 - acc: 0.9981Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0055 - acc: 0.9980 - val_loss: 0.1825 - val_acc: 0.9670\n",
      "Epoch 15/50\n",
      "311/314 [============================>.] - ETA: 0s - loss: 0.0048 - acc: 0.9983Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0048 - acc: 0.9983 - val_loss: 0.1997 - val_acc: 0.9650\n",
      "Epoch 16/50\n",
      "313/314 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.9987Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0036 - acc: 0.9987 - val_loss: 0.2164 - val_acc: 0.9658\n",
      "Epoch 17/50\n",
      "311/314 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.9988Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0036 - acc: 0.9988 - val_loss: 0.2245 - val_acc: 0.9656\n",
      "Epoch 18/50\n",
      "308/314 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.9990Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0030 - acc: 0.9989 - val_loss: 0.2327 - val_acc: 0.9653\n",
      "Epoch 19/50\n",
      "310/314 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.9991Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0027 - acc: 0.9991 - val_loss: 0.2380 - val_acc: 0.9658\n",
      "Epoch 20/50\n",
      "310/314 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9992Epoch 1/50\n",
      "314/314 [==============================] - 3s 10ms/step - loss: 0.0024 - acc: 0.9992 - val_loss: 0.2331 - val_acc: 0.9664\n",
      "Epoch 21/50\n",
      "309/314 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9993Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0021 - acc: 0.9993 - val_loss: 0.2430 - val_acc: 0.9665\n",
      "Epoch 22/50\n",
      "310/314 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9994Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0017 - acc: 0.9994 - val_loss: 0.2586 - val_acc: 0.9661\n",
      "Epoch 23/50\n",
      "308/314 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9993Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0021 - acc: 0.9993 - val_loss: 0.2634 - val_acc: 0.9663\n",
      "Epoch 24/50\n",
      "307/314 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9993Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0021 - acc: 0.9993 - val_loss: 0.2591 - val_acc: 0.9659\n",
      "Epoch 25/50\n",
      "313/314 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9994Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0017 - acc: 0.9994 - val_loss: 0.2669 - val_acc: 0.9659\n",
      "Epoch 26/50\n",
      "308/314 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 0.9996Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0012 - acc: 0.9996 - val_loss: 0.2943 - val_acc: 0.9654\n",
      "Epoch 27/50\n",
      "313/314 [============================>.] - ETA: 0s - loss: 0.0010 - acc: 0.9997   Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0010 - acc: 0.9997 - val_loss: 0.2792 - val_acc: 0.9658\n",
      "Epoch 28/50\n",
      "308/314 [============================>.] - ETA: 0s - loss: 9.9443e-04 - acc: 0.9997Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 9.9366e-04 - acc: 0.9997 - val_loss: 0.2875 - val_acc: 0.9664\n",
      "Epoch 29/50\n",
      "313/314 [============================>.] - ETA: 0s - loss: 0.0011 - acc: 0.9996Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0011 - acc: 0.9996 - val_loss: 0.2770 - val_acc: 0.9667\n",
      "Epoch 30/50\n",
      "310/314 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9995Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0015 - acc: 0.9995 - val_loss: 0.2828 - val_acc: 0.9667\n",
      "Epoch 31/50\n",
      "308/314 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 0.9996Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0012 - acc: 0.9996 - val_loss: 0.2911 - val_acc: 0.9659\n",
      "Epoch 32/50\n",
      "311/314 [============================>.] - ETA: 0s - loss: 9.2226e-04 - acc: 0.9997Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 9.1893e-04 - acc: 0.9997 - val_loss: 0.3170 - val_acc: 0.9651\n",
      "Epoch 33/50\n",
      "310/314 [============================>.] - ETA: 0s - loss: 0.0010 - acc: 0.9997 Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0010 - acc: 0.9997 - val_loss: 0.2973 - val_acc: 0.9662\n",
      "Epoch 34/50\n",
      "307/314 [============================>.] - ETA: 0s - loss: 0.0010 - acc: 0.9997Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0010 - acc: 0.9997 - val_loss: 0.2890 - val_acc: 0.9663\n",
      "Epoch 35/50\n",
      "313/314 [============================>.] - ETA: 0s - loss: 7.5295e-04 - acc: 0.9998Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 7.5077e-04 - acc: 0.9998 - val_loss: 0.3366 - val_acc: 0.9651\n",
      "Epoch 36/50\n",
      "310/314 [============================>.] - ETA: 0s - loss: 7.1041e-04 - acc: 0.9998Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 7.3477e-04 - acc: 0.9998 - val_loss: 0.3282 - val_acc: 0.9656\n",
      "Epoch 37/50\n",
      "310/314 [============================>.] - ETA: 0s - loss: 8.9439e-04 - acc: 0.9997Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 8.8677e-04 - acc: 0.9997 - val_loss: 0.3238 - val_acc: 0.9655\n",
      "Epoch 38/50\n",
      "310/314 [============================>.] - ETA: 0s - loss: 6.2692e-04 - acc: 0.9998Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 6.2116e-04 - acc: 0.9998 - val_loss: 0.3311 - val_acc: 0.9653\n",
      "Epoch 39/50\n",
      "310/314 [============================>.] - ETA: 0s - loss: 5.7642e-04 - acc: 0.9998Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 5.8350e-04 - acc: 0.9998 - val_loss: 0.3028 - val_acc: 0.9662\n",
      "Epoch 40/50\n",
      "310/314 [============================>.] - ETA: 0s - loss: 8.6986e-04 - acc: 0.9997Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 8.7846e-04 - acc: 0.9997 - val_loss: 0.2885 - val_acc: 0.9660\n",
      "Epoch 41/50\n",
      "313/314 [============================>.] - ETA: 0s - loss: 0.0011 - acc: 0.9997Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.2901 - val_acc: 0.9663\n",
      "Epoch 42/50\n",
      "309/314 [============================>.] - ETA: 0s - loss: 6.8352e-04 - acc: 0.9998Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 6.7790e-04 - acc: 0.9998 - val_loss: 0.3204 - val_acc: 0.9654\n",
      "Epoch 43/50\n",
      "313/314 [============================>.] - ETA: 0s - loss: 3.9489e-04 - acc: 0.9999Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 3.9374e-04 - acc: 0.9999 - val_loss: 0.3121 - val_acc: 0.9662\n",
      "Epoch 44/50\n",
      "313/314 [============================>.] - ETA: 0s - loss: 5.0317e-04 - acc: 0.9999Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 5.0174e-04 - acc: 0.9999 - val_loss: 0.3148 - val_acc: 0.9664\n",
      "Epoch 45/50\n",
      "310/314 [============================>.] - ETA: 0s - loss: 8.3375e-04 - acc: 0.9998Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 8.2921e-04 - acc: 0.9998 - val_loss: 0.3245 - val_acc: 0.9662\n",
      "Epoch 46/50\n",
      "311/314 [============================>.] - ETA: 0s - loss: 6.3568e-04 - acc: 0.9998Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 6.3253e-04 - acc: 0.9998 - val_loss: 0.3305 - val_acc: 0.9652\n",
      "Epoch 47/50\n",
      "311/314 [============================>.] - ETA: 0s - loss: 4.0056e-04 - acc: 0.9999Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 4.1043e-04 - acc: 0.9999 - val_loss: 0.3331 - val_acc: 0.9659\n",
      "Epoch 48/50\n",
      "307/314 [============================>.] - ETA: 0s - loss: 3.4769e-04 - acc: 0.9999Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 3.5237e-04 - acc: 0.9999 - val_loss: 0.3311 - val_acc: 0.9662\n",
      "Epoch 49/50\n",
      "309/314 [============================>.] - ETA: 0s - loss: 3.9876e-04 - acc: 0.9999Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 3.9867e-04 - acc: 0.9999 - val_loss: 0.3203 - val_acc: 0.9667\n",
      "Epoch 50/50\n",
      "312/314 [============================>.] - ETA: 0s - loss: 9.9930e-04 - acc: 0.9997Epoch 1/50\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 9.9803e-04 - acc: 0.9997 - val_loss: 0.3211 - val_acc: 0.9657\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26ba9c0c940>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BiLSTM_Model()\n",
    "#valid_x, valid_y = trainx[:250], trainy[:250]\n",
    "model.fit(store_data_trainx, store_data_trainy, store_data_devx, store_data_devy,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           precision    recall  f1-score   support\n",
      "\n",
      "        B     0.8290    0.7096    0.7647     31293\n",
      "\n",
      "micro avg     0.8290    0.7096    0.7647     31293\n",
      "macro avg     0.8290    0.7096    0.7647     31293\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'           precision    recall  f1-score   support\\n\\n        B     0.8290    0.7096    0.7647     31293\\n\\nmicro avg     0.8290    0.7096    0.7647     31293\\nmacro avg     0.8290    0.7096    0.7647     31293\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 验证模型，此方法将打印出详细的验证报告\n",
    "model.evaluate(store_data_testx, store_data_testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kashgari.embeddings import BERTEmbedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:seq_len: 200\n"
     ]
    }
   ],
   "source": [
    "bert_embed = BERTEmbedding('wwm_cased_L-24_H-1024_A-16',task=kashgari.LABELING,sequence_length=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Sequence length will auto set at 95% of sequence length\n",
      "WARNING:root:Model will be built until sequence length is determined\n"
     ]
    }
   ],
   "source": [
    "bert_embed = BERTEmbedding('biobert_large',task=kashgari.LABELING,sequence_length=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:seq_len: 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_17\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input-Token (InputLayer)        [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Input-Segment (InputLayer)      [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token (TokenEmbedding [(None, 50, 1024), ( 60411904    Input-Token[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Segment (Embedding)   (None, 50, 1024)     2048        Input-Segment[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token-Segment (Add)   (None, 50, 1024)     0           Embedding-Token[0][0]            \n",
      "                                                                 Embedding-Segment[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Position (PositionEmb (None, 50, 1024)     51200       Embedding-Token-Segment[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Dropout (Dropout)     (None, 50, 1024)     0           Embedding-Position[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Norm (LayerNormalizat (None, 50, 1024)     2048        Embedding-Dropout[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 50, 1024)     4198400     Embedding-Norm[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 50, 1024)     0           Encoder-1-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 50, 1024)     0           Embedding-Norm[0][0]             \n",
      "                                                                 Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 50, 1024)     2048        Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward (FeedForw (None, 50, 1024)     8393728     Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Dropout ( (None, 50, 1024)     0           Encoder-1-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Add (Add) (None, 50, 1024)     0           Encoder-1-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-1-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Norm (Lay (None, 50, 1024)     2048        Encoder-1-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 50, 1024)     4198400     Encoder-1-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 50, 1024)     0           Encoder-2-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 50, 1024)     0           Encoder-1-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 50, 1024)     2048        Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward (FeedForw (None, 50, 1024)     8393728     Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Dropout ( (None, 50, 1024)     0           Encoder-2-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Add (Add) (None, 50, 1024)     0           Encoder-2-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-2-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Norm (Lay (None, 50, 1024)     2048        Encoder-2-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 50, 1024)     4198400     Encoder-2-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 50, 1024)     0           Encoder-3-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 50, 1024)     0           Encoder-2-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 50, 1024)     2048        Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward (FeedForw (None, 50, 1024)     8393728     Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Dropout ( (None, 50, 1024)     0           Encoder-3-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Add (Add) (None, 50, 1024)     0           Encoder-3-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-3-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Norm (Lay (None, 50, 1024)     2048        Encoder-3-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 50, 1024)     4198400     Encoder-3-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 50, 1024)     0           Encoder-4-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 50, 1024)     0           Encoder-3-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 50, 1024)     2048        Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward (FeedForw (None, 50, 1024)     8393728     Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Dropout ( (None, 50, 1024)     0           Encoder-4-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Add (Add) (None, 50, 1024)     0           Encoder-4-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-4-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Norm (Lay (None, 50, 1024)     2048        Encoder-4-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 50, 1024)     4198400     Encoder-4-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 50, 1024)     0           Encoder-5-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 50, 1024)     0           Encoder-4-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 50, 1024)     2048        Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward (FeedForw (None, 50, 1024)     8393728     Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Dropout ( (None, 50, 1024)     0           Encoder-5-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Add (Add) (None, 50, 1024)     0           Encoder-5-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-5-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Norm (Lay (None, 50, 1024)     2048        Encoder-5-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 50, 1024)     4198400     Encoder-5-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 50, 1024)     0           Encoder-6-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 50, 1024)     0           Encoder-5-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 50, 1024)     2048        Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward (FeedForw (None, 50, 1024)     8393728     Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Dropout ( (None, 50, 1024)     0           Encoder-6-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Add (Add) (None, 50, 1024)     0           Encoder-6-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-6-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Norm (Lay (None, 50, 1024)     2048        Encoder-6-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 50, 1024)     4198400     Encoder-6-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 50, 1024)     0           Encoder-7-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 50, 1024)     0           Encoder-6-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 50, 1024)     2048        Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward (FeedForw (None, 50, 1024)     8393728     Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Dropout ( (None, 50, 1024)     0           Encoder-7-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Add (Add) (None, 50, 1024)     0           Encoder-7-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-7-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Norm (Lay (None, 50, 1024)     2048        Encoder-7-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 50, 1024)     4198400     Encoder-7-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 50, 1024)     0           Encoder-8-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 50, 1024)     0           Encoder-7-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 50, 1024)     2048        Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward (FeedForw (None, 50, 1024)     8393728     Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Dropout ( (None, 50, 1024)     0           Encoder-8-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Add (Add) (None, 50, 1024)     0           Encoder-8-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-8-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Norm (Lay (None, 50, 1024)     2048        Encoder-8-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 50, 1024)     4198400     Encoder-8-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 50, 1024)     0           Encoder-9-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 50, 1024)     0           Encoder-8-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 50, 1024)     2048        Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward (FeedForw (None, 50, 1024)     8393728     Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Dropout ( (None, 50, 1024)     0           Encoder-9-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Add (Add) (None, 50, 1024)     0           Encoder-9-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-9-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Norm (Lay (None, 50, 1024)     2048        Encoder-9-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 50, 1024)     4198400     Encoder-9-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-9-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 50, 1024)     2048        Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward (FeedFor (None, 50, 1024)     8393728     Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Dropout  (None, 50, 1024)     0           Encoder-10-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Add (Add (None, 50, 1024)     0           Encoder-10-MultiHeadSelfAttention\n",
      "                                                                 Encoder-10-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Norm (La (None, 50, 1024)     2048        Encoder-10-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 50, 1024)     4198400     Encoder-10-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-10-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 50, 1024)     2048        Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward (FeedFor (None, 50, 1024)     8393728     Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Dropout  (None, 50, 1024)     0           Encoder-11-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Add (Add (None, 50, 1024)     0           Encoder-11-MultiHeadSelfAttention\n",
      "                                                                 Encoder-11-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Norm (La (None, 50, 1024)     2048        Encoder-11-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 50, 1024)     4198400     Encoder-11-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-11-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 50, 1024)     2048        Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward (FeedFor (None, 50, 1024)     8393728     Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Dropout  (None, 50, 1024)     0           Encoder-12-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Add (Add (None, 50, 1024)     0           Encoder-12-MultiHeadSelfAttention\n",
      "                                                                 Encoder-12-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Norm (La (None, 50, 1024)     2048        Encoder-12-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-13-MultiHeadSelfAttenti (None, 50, 1024)     4198400     Encoder-12-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-13-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-13-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-13-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-12-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-13-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-13-MultiHeadSelfAttenti (None, 50, 1024)     2048        Encoder-13-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-13-FeedForward (FeedFor (None, 50, 1024)     8393728     Encoder-13-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-13-FeedForward-Dropout  (None, 50, 1024)     0           Encoder-13-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-13-FeedForward-Add (Add (None, 50, 1024)     0           Encoder-13-MultiHeadSelfAttention\n",
      "                                                                 Encoder-13-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-13-FeedForward-Norm (La (None, 50, 1024)     2048        Encoder-13-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-14-MultiHeadSelfAttenti (None, 50, 1024)     4198400     Encoder-13-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-14-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-14-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-14-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-13-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-14-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-14-MultiHeadSelfAttenti (None, 50, 1024)     2048        Encoder-14-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-14-FeedForward (FeedFor (None, 50, 1024)     8393728     Encoder-14-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-14-FeedForward-Dropout  (None, 50, 1024)     0           Encoder-14-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-14-FeedForward-Add (Add (None, 50, 1024)     0           Encoder-14-MultiHeadSelfAttention\n",
      "                                                                 Encoder-14-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-14-FeedForward-Norm (La (None, 50, 1024)     2048        Encoder-14-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-15-MultiHeadSelfAttenti (None, 50, 1024)     4198400     Encoder-14-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-15-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-15-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-15-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-14-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-15-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-15-MultiHeadSelfAttenti (None, 50, 1024)     2048        Encoder-15-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-15-FeedForward (FeedFor (None, 50, 1024)     8393728     Encoder-15-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-15-FeedForward-Dropout  (None, 50, 1024)     0           Encoder-15-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-15-FeedForward-Add (Add (None, 50, 1024)     0           Encoder-15-MultiHeadSelfAttention\n",
      "                                                                 Encoder-15-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-15-FeedForward-Norm (La (None, 50, 1024)     2048        Encoder-15-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-16-MultiHeadSelfAttenti (None, 50, 1024)     4198400     Encoder-15-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-16-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-16-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-16-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-15-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-16-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-16-MultiHeadSelfAttenti (None, 50, 1024)     2048        Encoder-16-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-16-FeedForward (FeedFor (None, 50, 1024)     8393728     Encoder-16-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-16-FeedForward-Dropout  (None, 50, 1024)     0           Encoder-16-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-16-FeedForward-Add (Add (None, 50, 1024)     0           Encoder-16-MultiHeadSelfAttention\n",
      "                                                                 Encoder-16-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-16-FeedForward-Norm (La (None, 50, 1024)     2048        Encoder-16-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-17-MultiHeadSelfAttenti (None, 50, 1024)     4198400     Encoder-16-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-17-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-17-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-17-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-16-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-17-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-17-MultiHeadSelfAttenti (None, 50, 1024)     2048        Encoder-17-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-17-FeedForward (FeedFor (None, 50, 1024)     8393728     Encoder-17-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-17-FeedForward-Dropout  (None, 50, 1024)     0           Encoder-17-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-17-FeedForward-Add (Add (None, 50, 1024)     0           Encoder-17-MultiHeadSelfAttention\n",
      "                                                                 Encoder-17-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-17-FeedForward-Norm (La (None, 50, 1024)     2048        Encoder-17-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-18-MultiHeadSelfAttenti (None, 50, 1024)     4198400     Encoder-17-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-18-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-18-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-18-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-17-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-18-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-18-MultiHeadSelfAttenti (None, 50, 1024)     2048        Encoder-18-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-18-FeedForward (FeedFor (None, 50, 1024)     8393728     Encoder-18-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-18-FeedForward-Dropout  (None, 50, 1024)     0           Encoder-18-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-18-FeedForward-Add (Add (None, 50, 1024)     0           Encoder-18-MultiHeadSelfAttention\n",
      "                                                                 Encoder-18-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-18-FeedForward-Norm (La (None, 50, 1024)     2048        Encoder-18-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-19-MultiHeadSelfAttenti (None, 50, 1024)     4198400     Encoder-18-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-19-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-19-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-19-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-18-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-19-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-19-MultiHeadSelfAttenti (None, 50, 1024)     2048        Encoder-19-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-19-FeedForward (FeedFor (None, 50, 1024)     8393728     Encoder-19-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-19-FeedForward-Dropout  (None, 50, 1024)     0           Encoder-19-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-19-FeedForward-Add (Add (None, 50, 1024)     0           Encoder-19-MultiHeadSelfAttention\n",
      "                                                                 Encoder-19-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-19-FeedForward-Norm (La (None, 50, 1024)     2048        Encoder-19-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-20-MultiHeadSelfAttenti (None, 50, 1024)     4198400     Encoder-19-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-20-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-20-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-20-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-19-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-20-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-20-MultiHeadSelfAttenti (None, 50, 1024)     2048        Encoder-20-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-20-FeedForward (FeedFor (None, 50, 1024)     8393728     Encoder-20-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-20-FeedForward-Dropout  (None, 50, 1024)     0           Encoder-20-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-20-FeedForward-Add (Add (None, 50, 1024)     0           Encoder-20-MultiHeadSelfAttention\n",
      "                                                                 Encoder-20-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-20-FeedForward-Norm (La (None, 50, 1024)     2048        Encoder-20-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-21-MultiHeadSelfAttenti (None, 50, 1024)     4198400     Encoder-20-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-21-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-21-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-21-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-20-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-21-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-21-MultiHeadSelfAttenti (None, 50, 1024)     2048        Encoder-21-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-21-FeedForward (FeedFor (None, 50, 1024)     8393728     Encoder-21-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-21-FeedForward-Dropout  (None, 50, 1024)     0           Encoder-21-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-21-FeedForward-Add (Add (None, 50, 1024)     0           Encoder-21-MultiHeadSelfAttention\n",
      "                                                                 Encoder-21-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-21-FeedForward-Norm (La (None, 50, 1024)     2048        Encoder-21-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-22-MultiHeadSelfAttenti (None, 50, 1024)     4198400     Encoder-21-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-22-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-22-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-22-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-21-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-22-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-22-MultiHeadSelfAttenti (None, 50, 1024)     2048        Encoder-22-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-22-FeedForward (FeedFor (None, 50, 1024)     8393728     Encoder-22-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-22-FeedForward-Dropout  (None, 50, 1024)     0           Encoder-22-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-22-FeedForward-Add (Add (None, 50, 1024)     0           Encoder-22-MultiHeadSelfAttention\n",
      "                                                                 Encoder-22-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-22-FeedForward-Norm (La (None, 50, 1024)     2048        Encoder-22-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-23-MultiHeadSelfAttenti (None, 50, 1024)     4198400     Encoder-22-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-23-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-23-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-23-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-22-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-23-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-23-MultiHeadSelfAttenti (None, 50, 1024)     2048        Encoder-23-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-23-FeedForward (FeedFor (None, 50, 1024)     8393728     Encoder-23-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-23-FeedForward-Dropout  (None, 50, 1024)     0           Encoder-23-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-23-FeedForward-Add (Add (None, 50, 1024)     0           Encoder-23-MultiHeadSelfAttention\n",
      "                                                                 Encoder-23-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-23-FeedForward-Norm (La (None, 50, 1024)     2048        Encoder-23-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-24-MultiHeadSelfAttenti (None, 50, 1024)     4198400     Encoder-23-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-24-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-24-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-24-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-23-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-24-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-24-MultiHeadSelfAttenti (None, 50, 1024)     2048        Encoder-24-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-24-FeedForward (FeedFor (None, 50, 1024)     8393728     Encoder-24-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-24-FeedForward-Dropout  (None, 50, 1024)     0           Encoder-24-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-24-FeedForward-Add (Add (None, 50, 1024)     0           Encoder-24-MultiHeadSelfAttention\n",
      "                                                                 Encoder-24-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-24-FeedForward-Norm (La (None, 50, 1024)     2048        Encoder-24-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Output (Concatenate)    (None, 50, 4096)     0           Encoder-21-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-22-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-23-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-24-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "non_masking_layer_1 (NonMasking (None, 50, 4096)     0           Encoder-Output[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_blstm (Bidirectional)     (None, 50, 256)      4327424     non_masking_layer_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "layer_dropout (Dropout)         (None, 50, 256)      0           layer_blstm[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "layer_time_distributed (TimeDis (None, 50, 3)        771         layer_dropout[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 50, 3)        0           layer_time_distributed[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 367,104,771\n",
      "Trainable params: 4,328,195\n",
      "Non-trainable params: 362,776,576\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "313/314 [============================>.] - ETA: 0s - loss: 0.0906 - acc: 0.9591Epoch 1/10\n",
      "314/314 [==============================] - 232s 740ms/step - loss: 0.0906 - acc: 0.9591 - val_loss: 0.0785 - val_acc: 0.9617\n",
      "Epoch 2/10\n",
      "313/314 [============================>.] - ETA: 0s - loss: 0.0690 - acc: 0.9680Epoch 1/10\n",
      "314/314 [==============================] - 218s 693ms/step - loss: 0.0691 - acc: 0.9680 - val_loss: 0.0732 - val_acc: 0.9652\n",
      "Epoch 3/10\n",
      "313/314 [============================>.] - ETA: 0s - loss: 0.0649 - acc: 0.9700Epoch 1/10\n",
      "314/314 [==============================] - 219s 696ms/step - loss: 0.0648 - acc: 0.9700 - val_loss: 0.0720 - val_acc: 0.9647\n",
      "Epoch 4/10\n",
      "313/314 [============================>.] - ETA: 0s - loss: 0.0618 - acc: 0.9714Epoch 1/10\n",
      "314/314 [==============================] - 217s 691ms/step - loss: 0.0617 - acc: 0.9714 - val_loss: 0.0741 - val_acc: 0.9637\n",
      "Epoch 5/10\n",
      "313/314 [============================>.] - ETA: 0s - loss: 0.0598 - acc: 0.9723Epoch 1/10\n",
      "314/314 [==============================] - 216s 689ms/step - loss: 0.0598 - acc: 0.9723 - val_loss: 0.0705 - val_acc: 0.9664\n",
      "Epoch 6/10\n",
      "313/314 [============================>.] - ETA: 0s - loss: 0.0584 - acc: 0.9728Epoch 1/10\n",
      "314/314 [==============================] - 221s 702ms/step - loss: 0.0584 - acc: 0.9728 - val_loss: 0.0714 - val_acc: 0.9655\n",
      "Epoch 7/10\n",
      "313/314 [============================>.] - ETA: 0s - loss: 0.0567 - acc: 0.9735Epoch 1/10\n",
      "314/314 [==============================] - 220s 702ms/step - loss: 0.0566 - acc: 0.9735 - val_loss: 0.0717 - val_acc: 0.9657\n",
      "Epoch 8/10\n",
      "313/314 [============================>.] - ETA: 0s - loss: 0.0555 - acc: 0.9744Epoch 1/10\n",
      "314/314 [==============================] - 218s 695ms/step - loss: 0.0554 - acc: 0.9744 - val_loss: 0.0711 - val_acc: 0.9662\n",
      "Epoch 9/10\n",
      "313/314 [============================>.] - ETA: 0s - loss: 0.0544 - acc: 0.9748Epoch 1/10\n",
      "314/314 [==============================] - 217s 691ms/step - loss: 0.0543 - acc: 0.9748 - val_loss: 0.0707 - val_acc: 0.9660\n",
      "Epoch 10/10\n",
      "313/314 [============================>.] - ETA: 0s - loss: 0.0534 - acc: 0.9752Epoch 1/10\n",
      "314/314 [==============================] - 217s 691ms/step - loss: 0.0534 - acc: 0.9752 - val_loss: 0.0713 - val_acc: 0.9661\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27ecde6f668>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BiLSTM_Model(bert_embed)\n",
    "#valid_x, valid_y = trainx[:250], trainy[:250]\n",
    "model.fit(store_data_trainx, store_data_trainy, store_data_devx, store_data_devy,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           precision    recall  f1-score   support\n",
      "\n",
      "        B     0.7542    0.7699    0.7620     31241\n",
      "\n",
      "micro avg     0.7542    0.7699    0.7620     31241\n",
      "macro avg     0.7542    0.7699    0.7620     31241\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'           precision    recall  f1-score   support\\n\\n        B     0.7542    0.7699    0.7620     31241\\n\\nmicro avg     0.7542    0.7699    0.7620     31241\\nmacro avg     0.7542    0.7699    0.7620     31241\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 验证模型，此方法将打印出详细的验证报告  10\n",
    "model.evaluate(store_data_testx, store_data_testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:CuDNN enabled, this will speed up the training, but will make model incompatible with CPU device.\n"
     ]
    }
   ],
   "source": [
    "import kashgari\n",
    "kashgari.config.use_cudnn_cell = True\n",
    "from kashgari.tasks.labeling import BiLSTM_CRF_Model   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Sequence length will auto set at 95% of sequence length\n",
      "WARNING:root:Model will be built until sequence length is determined\n"
     ]
    }
   ],
   "source": [
    "from kashgari.embeddings import BERTEmbedding\n",
    "bert_embed = BERTEmbedding('biobert_large',task=kashgari.LABELING,sequence_length=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:seq_len: 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_22\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input-Token (InputLayer)        [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Input-Segment (InputLayer)      [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token (TokenEmbedding [(None, 50, 1024), ( 60411904    Input-Token[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Segment (Embedding)   (None, 50, 1024)     2048        Input-Segment[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token-Segment (Add)   (None, 50, 1024)     0           Embedding-Token[0][0]            \n",
      "                                                                 Embedding-Segment[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Position (PositionEmb (None, 50, 1024)     51200       Embedding-Token-Segment[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Dropout (Dropout)     (None, 50, 1024)     0           Embedding-Position[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Norm (LayerNormalizat (None, 50, 1024)     2048        Embedding-Dropout[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 50, 1024)     4198400     Embedding-Norm[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 50, 1024)     0           Encoder-1-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 50, 1024)     0           Embedding-Norm[0][0]             \n",
      "                                                                 Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 50, 1024)     2048        Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward (FeedForw (None, 50, 1024)     8393728     Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Dropout ( (None, 50, 1024)     0           Encoder-1-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Add (Add) (None, 50, 1024)     0           Encoder-1-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-1-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Norm (Lay (None, 50, 1024)     2048        Encoder-1-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 50, 1024)     4198400     Encoder-1-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 50, 1024)     0           Encoder-2-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 50, 1024)     0           Encoder-1-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 50, 1024)     2048        Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward (FeedForw (None, 50, 1024)     8393728     Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Dropout ( (None, 50, 1024)     0           Encoder-2-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Add (Add) (None, 50, 1024)     0           Encoder-2-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-2-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Norm (Lay (None, 50, 1024)     2048        Encoder-2-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 50, 1024)     4198400     Encoder-2-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 50, 1024)     0           Encoder-3-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 50, 1024)     0           Encoder-2-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 50, 1024)     2048        Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward (FeedForw (None, 50, 1024)     8393728     Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Dropout ( (None, 50, 1024)     0           Encoder-3-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Add (Add) (None, 50, 1024)     0           Encoder-3-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-3-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Norm (Lay (None, 50, 1024)     2048        Encoder-3-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 50, 1024)     4198400     Encoder-3-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 50, 1024)     0           Encoder-4-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 50, 1024)     0           Encoder-3-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 50, 1024)     2048        Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward (FeedForw (None, 50, 1024)     8393728     Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Dropout ( (None, 50, 1024)     0           Encoder-4-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Add (Add) (None, 50, 1024)     0           Encoder-4-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-4-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Norm (Lay (None, 50, 1024)     2048        Encoder-4-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 50, 1024)     4198400     Encoder-4-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 50, 1024)     0           Encoder-5-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 50, 1024)     0           Encoder-4-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 50, 1024)     2048        Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward (FeedForw (None, 50, 1024)     8393728     Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Dropout ( (None, 50, 1024)     0           Encoder-5-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Add (Add) (None, 50, 1024)     0           Encoder-5-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-5-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Norm (Lay (None, 50, 1024)     2048        Encoder-5-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 50, 1024)     4198400     Encoder-5-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 50, 1024)     0           Encoder-6-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 50, 1024)     0           Encoder-5-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 50, 1024)     2048        Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward (FeedForw (None, 50, 1024)     8393728     Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Dropout ( (None, 50, 1024)     0           Encoder-6-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Add (Add) (None, 50, 1024)     0           Encoder-6-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-6-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Norm (Lay (None, 50, 1024)     2048        Encoder-6-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 50, 1024)     4198400     Encoder-6-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 50, 1024)     0           Encoder-7-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 50, 1024)     0           Encoder-6-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 50, 1024)     2048        Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward (FeedForw (None, 50, 1024)     8393728     Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Dropout ( (None, 50, 1024)     0           Encoder-7-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Add (Add) (None, 50, 1024)     0           Encoder-7-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-7-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Norm (Lay (None, 50, 1024)     2048        Encoder-7-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 50, 1024)     4198400     Encoder-7-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 50, 1024)     0           Encoder-8-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 50, 1024)     0           Encoder-7-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 50, 1024)     2048        Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward (FeedForw (None, 50, 1024)     8393728     Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Dropout ( (None, 50, 1024)     0           Encoder-8-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Add (Add) (None, 50, 1024)     0           Encoder-8-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-8-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Norm (Lay (None, 50, 1024)     2048        Encoder-8-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 50, 1024)     4198400     Encoder-8-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 50, 1024)     0           Encoder-9-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 50, 1024)     0           Encoder-8-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 50, 1024)     2048        Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward (FeedForw (None, 50, 1024)     8393728     Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Dropout ( (None, 50, 1024)     0           Encoder-9-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Add (Add) (None, 50, 1024)     0           Encoder-9-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-9-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Norm (Lay (None, 50, 1024)     2048        Encoder-9-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 50, 1024)     4198400     Encoder-9-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-9-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 50, 1024)     2048        Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward (FeedFor (None, 50, 1024)     8393728     Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Dropout  (None, 50, 1024)     0           Encoder-10-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Add (Add (None, 50, 1024)     0           Encoder-10-MultiHeadSelfAttention\n",
      "                                                                 Encoder-10-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Norm (La (None, 50, 1024)     2048        Encoder-10-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 50, 1024)     4198400     Encoder-10-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-10-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 50, 1024)     2048        Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward (FeedFor (None, 50, 1024)     8393728     Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Dropout  (None, 50, 1024)     0           Encoder-11-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Add (Add (None, 50, 1024)     0           Encoder-11-MultiHeadSelfAttention\n",
      "                                                                 Encoder-11-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Norm (La (None, 50, 1024)     2048        Encoder-11-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 50, 1024)     4198400     Encoder-11-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-11-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 50, 1024)     2048        Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward (FeedFor (None, 50, 1024)     8393728     Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Dropout  (None, 50, 1024)     0           Encoder-12-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Add (Add (None, 50, 1024)     0           Encoder-12-MultiHeadSelfAttention\n",
      "                                                                 Encoder-12-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Norm (La (None, 50, 1024)     2048        Encoder-12-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-13-MultiHeadSelfAttenti (None, 50, 1024)     4198400     Encoder-12-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-13-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-13-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-13-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-12-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-13-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-13-MultiHeadSelfAttenti (None, 50, 1024)     2048        Encoder-13-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-13-FeedForward (FeedFor (None, 50, 1024)     8393728     Encoder-13-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-13-FeedForward-Dropout  (None, 50, 1024)     0           Encoder-13-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-13-FeedForward-Add (Add (None, 50, 1024)     0           Encoder-13-MultiHeadSelfAttention\n",
      "                                                                 Encoder-13-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-13-FeedForward-Norm (La (None, 50, 1024)     2048        Encoder-13-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-14-MultiHeadSelfAttenti (None, 50, 1024)     4198400     Encoder-13-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-14-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-14-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-14-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-13-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-14-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-14-MultiHeadSelfAttenti (None, 50, 1024)     2048        Encoder-14-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-14-FeedForward (FeedFor (None, 50, 1024)     8393728     Encoder-14-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-14-FeedForward-Dropout  (None, 50, 1024)     0           Encoder-14-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-14-FeedForward-Add (Add (None, 50, 1024)     0           Encoder-14-MultiHeadSelfAttention\n",
      "                                                                 Encoder-14-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-14-FeedForward-Norm (La (None, 50, 1024)     2048        Encoder-14-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-15-MultiHeadSelfAttenti (None, 50, 1024)     4198400     Encoder-14-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-15-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-15-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-15-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-14-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-15-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-15-MultiHeadSelfAttenti (None, 50, 1024)     2048        Encoder-15-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-15-FeedForward (FeedFor (None, 50, 1024)     8393728     Encoder-15-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-15-FeedForward-Dropout  (None, 50, 1024)     0           Encoder-15-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-15-FeedForward-Add (Add (None, 50, 1024)     0           Encoder-15-MultiHeadSelfAttention\n",
      "                                                                 Encoder-15-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-15-FeedForward-Norm (La (None, 50, 1024)     2048        Encoder-15-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-16-MultiHeadSelfAttenti (None, 50, 1024)     4198400     Encoder-15-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-16-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-16-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-16-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-15-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-16-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-16-MultiHeadSelfAttenti (None, 50, 1024)     2048        Encoder-16-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-16-FeedForward (FeedFor (None, 50, 1024)     8393728     Encoder-16-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-16-FeedForward-Dropout  (None, 50, 1024)     0           Encoder-16-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-16-FeedForward-Add (Add (None, 50, 1024)     0           Encoder-16-MultiHeadSelfAttention\n",
      "                                                                 Encoder-16-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-16-FeedForward-Norm (La (None, 50, 1024)     2048        Encoder-16-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-17-MultiHeadSelfAttenti (None, 50, 1024)     4198400     Encoder-16-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-17-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-17-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-17-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-16-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-17-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-17-MultiHeadSelfAttenti (None, 50, 1024)     2048        Encoder-17-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-17-FeedForward (FeedFor (None, 50, 1024)     8393728     Encoder-17-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-17-FeedForward-Dropout  (None, 50, 1024)     0           Encoder-17-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-17-FeedForward-Add (Add (None, 50, 1024)     0           Encoder-17-MultiHeadSelfAttention\n",
      "                                                                 Encoder-17-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-17-FeedForward-Norm (La (None, 50, 1024)     2048        Encoder-17-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-18-MultiHeadSelfAttenti (None, 50, 1024)     4198400     Encoder-17-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-18-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-18-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-18-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-17-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-18-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-18-MultiHeadSelfAttenti (None, 50, 1024)     2048        Encoder-18-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-18-FeedForward (FeedFor (None, 50, 1024)     8393728     Encoder-18-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-18-FeedForward-Dropout  (None, 50, 1024)     0           Encoder-18-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-18-FeedForward-Add (Add (None, 50, 1024)     0           Encoder-18-MultiHeadSelfAttention\n",
      "                                                                 Encoder-18-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-18-FeedForward-Norm (La (None, 50, 1024)     2048        Encoder-18-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-19-MultiHeadSelfAttenti (None, 50, 1024)     4198400     Encoder-18-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-19-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-19-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-19-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-18-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-19-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-19-MultiHeadSelfAttenti (None, 50, 1024)     2048        Encoder-19-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-19-FeedForward (FeedFor (None, 50, 1024)     8393728     Encoder-19-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-19-FeedForward-Dropout  (None, 50, 1024)     0           Encoder-19-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-19-FeedForward-Add (Add (None, 50, 1024)     0           Encoder-19-MultiHeadSelfAttention\n",
      "                                                                 Encoder-19-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-19-FeedForward-Norm (La (None, 50, 1024)     2048        Encoder-19-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-20-MultiHeadSelfAttenti (None, 50, 1024)     4198400     Encoder-19-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-20-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-20-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-20-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-19-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-20-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-20-MultiHeadSelfAttenti (None, 50, 1024)     2048        Encoder-20-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-20-FeedForward (FeedFor (None, 50, 1024)     8393728     Encoder-20-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-20-FeedForward-Dropout  (None, 50, 1024)     0           Encoder-20-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-20-FeedForward-Add (Add (None, 50, 1024)     0           Encoder-20-MultiHeadSelfAttention\n",
      "                                                                 Encoder-20-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-20-FeedForward-Norm (La (None, 50, 1024)     2048        Encoder-20-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-21-MultiHeadSelfAttenti (None, 50, 1024)     4198400     Encoder-20-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-21-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-21-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-21-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-20-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-21-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-21-MultiHeadSelfAttenti (None, 50, 1024)     2048        Encoder-21-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-21-FeedForward (FeedFor (None, 50, 1024)     8393728     Encoder-21-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-21-FeedForward-Dropout  (None, 50, 1024)     0           Encoder-21-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-21-FeedForward-Add (Add (None, 50, 1024)     0           Encoder-21-MultiHeadSelfAttention\n",
      "                                                                 Encoder-21-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-21-FeedForward-Norm (La (None, 50, 1024)     2048        Encoder-21-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-22-MultiHeadSelfAttenti (None, 50, 1024)     4198400     Encoder-21-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-22-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-22-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-22-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-21-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-22-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-22-MultiHeadSelfAttenti (None, 50, 1024)     2048        Encoder-22-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-22-FeedForward (FeedFor (None, 50, 1024)     8393728     Encoder-22-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-22-FeedForward-Dropout  (None, 50, 1024)     0           Encoder-22-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-22-FeedForward-Add (Add (None, 50, 1024)     0           Encoder-22-MultiHeadSelfAttention\n",
      "                                                                 Encoder-22-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-22-FeedForward-Norm (La (None, 50, 1024)     2048        Encoder-22-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-23-MultiHeadSelfAttenti (None, 50, 1024)     4198400     Encoder-22-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-23-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-23-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-23-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-22-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-23-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-23-MultiHeadSelfAttenti (None, 50, 1024)     2048        Encoder-23-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-23-FeedForward (FeedFor (None, 50, 1024)     8393728     Encoder-23-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-23-FeedForward-Dropout  (None, 50, 1024)     0           Encoder-23-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-23-FeedForward-Add (Add (None, 50, 1024)     0           Encoder-23-MultiHeadSelfAttention\n",
      "                                                                 Encoder-23-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-23-FeedForward-Norm (La (None, 50, 1024)     2048        Encoder-23-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-24-MultiHeadSelfAttenti (None, 50, 1024)     4198400     Encoder-23-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-24-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-24-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-24-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-23-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-24-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-24-MultiHeadSelfAttenti (None, 50, 1024)     2048        Encoder-24-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-24-FeedForward (FeedFor (None, 50, 1024)     8393728     Encoder-24-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-24-FeedForward-Dropout  (None, 50, 1024)     0           Encoder-24-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-24-FeedForward-Add (Add (None, 50, 1024)     0           Encoder-24-MultiHeadSelfAttention\n",
      "                                                                 Encoder-24-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-24-FeedForward-Norm (La (None, 50, 1024)     2048        Encoder-24-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Output (Concatenate)    (None, 50, 4096)     0           Encoder-21-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-22-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-23-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-24-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "non_masking_layer_2 (NonMasking (None, 50, 4096)     0           Encoder-Output[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_blstm (Bidirectional)     (None, 50, 256)      4327424     non_masking_layer_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "layer_dense (Dense)             (None, 50, 64)       16448       layer_blstm[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "layer_crf_dense (Dense)         (None, 50, 3)        195         layer_dense[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "layer_crf (CRF)                 (None, 50, 3)        9           layer_crf_dense[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 367,120,652\n",
      "Trainable params: 4,344,076\n",
      "Non-trainable params: 362,776,576\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "313/314 [============================>.] - ETA: 0s - loss: 4.8299 - accuracy: 0.9590Epoch 1/40\n",
      "314/314 [==============================] - 266s 848ms/step - loss: 4.8221 - accuracy: 0.9590 - val_loss: 27.0064 - val_accuracy: 0.8234\n",
      "Epoch 2/40\n",
      "313/314 [============================>.] - ETA: 0s - loss: 3.4858 - accuracy: 0.9690Epoch 1/40\n",
      "314/314 [==============================] - 258s 822ms/step - loss: 3.4838 - accuracy: 0.9690 - val_loss: 25.5063 - val_accuracy: 0.8226\n",
      "Epoch 3/40\n",
      "313/314 [============================>.] - ETA: 0s - loss: 3.1050 - accuracy: 0.9720Epoch 1/40\n",
      "314/314 [==============================] - 263s 837ms/step - loss: 3.1052 - accuracy: 0.9720 - val_loss: 24.0899 - val_accuracy: 0.8246\n",
      "Epoch 4/40\n",
      "313/314 [============================>.] - ETA: 0s - loss: 2.8575 - accuracy: 0.9738Epoch 1/40\n",
      "314/314 [==============================] - 262s 835ms/step - loss: 2.8604 - accuracy: 0.9738 - val_loss: 23.7578 - val_accuracy: 0.7220\n",
      "Epoch 5/40\n",
      "313/314 [============================>.] - ETA: 0s - loss: 2.6904 - accuracy: 0.9751Epoch 1/40\n",
      "314/314 [==============================] - 263s 836ms/step - loss: 2.6929 - accuracy: 0.9751 - val_loss: 23.3369 - val_accuracy: 0.6403\n",
      "Epoch 6/40\n",
      "313/314 [============================>.] - ETA: 0s - loss: 2.5648 - accuracy: 0.9762Epoch 1/40\n",
      "314/314 [==============================] - 264s 839ms/step - loss: 2.5645 - accuracy: 0.9762 - val_loss: 23.0908 - val_accuracy: 0.6512\n",
      "Epoch 7/40\n",
      "313/314 [============================>.] - ETA: 0s - loss: 2.4740 - accuracy: 0.9769Epoch 1/40\n",
      "314/314 [==============================] - 263s 837ms/step - loss: 2.4726 - accuracy: 0.9769 - val_loss: 22.9755 - val_accuracy: 0.6537\n",
      "Epoch 8/40\n",
      "313/314 [============================>.] - ETA: 0s - loss: 2.3876 - accuracy: 0.9777Epoch 1/40\n",
      "314/314 [==============================] - 263s 836ms/step - loss: 2.3830 - accuracy: 0.9777 - val_loss: 23.0260 - val_accuracy: 0.6524\n",
      "Epoch 9/40\n",
      "313/314 [============================>.] - ETA: 0s - loss: 2.3220 - accuracy: 0.9784Epoch 1/40\n",
      "314/314 [==============================] - 263s 836ms/step - loss: 2.3199 - accuracy: 0.9784 - val_loss: 22.9757 - val_accuracy: 0.6499\n",
      "Epoch 10/40\n",
      "313/314 [============================>.] - ETA: 0s - loss: 2.2416 - accuracy: 0.9792Epoch 1/40\n",
      "314/314 [==============================] - 264s 839ms/step - loss: 2.2402 - accuracy: 0.9792 - val_loss: 22.9666 - val_accuracy: 0.6492\n",
      "Epoch 11/40\n",
      "313/314 [============================>.] - ETA: 0s - loss: 2.1860 - accuracy: 0.9797Epoch 1/40\n",
      "314/314 [==============================] - 263s 839ms/step - loss: 2.1897 - accuracy: 0.9796 - val_loss: 22.9885 - val_accuracy: 0.6537\n",
      "Epoch 12/40\n",
      "313/314 [============================>.] - ETA: 0s - loss: 2.1386 - accuracy: 0.9800Epoch 1/40\n",
      "314/314 [==============================] - 263s 836ms/step - loss: 2.1384 - accuracy: 0.9800 - val_loss: 23.0072 - val_accuracy: 0.6527\n",
      "Epoch 13/40\n",
      "313/314 [============================>.] - ETA: 0s - loss: 2.1081 - accuracy: 0.9804Epoch 1/40\n",
      "314/314 [==============================] - 262s 835ms/step - loss: 2.1083 - accuracy: 0.9804 - val_loss: 22.9127 - val_accuracy: 0.6521\n",
      "Epoch 14/40\n",
      "313/314 [============================>.] - ETA: 0s - loss: 2.0339 - accuracy: 0.9813Epoch 1/40\n",
      "314/314 [==============================] - 262s 835ms/step - loss: 2.0346 - accuracy: 0.9813 - val_loss: 23.0484 - val_accuracy: 0.6509\n",
      "Epoch 15/40\n",
      "313/314 [============================>.] - ETA: 0s - loss: 2.0136 - accuracy: 0.9814Epoch 1/40\n",
      "314/314 [==============================] - 262s 836ms/step - loss: 2.0136 - accuracy: 0.9814 - val_loss: 22.7209 - val_accuracy: 0.6496\n",
      "Epoch 16/40\n",
      "313/314 [============================>.] - ETA: 0s - loss: 1.9626 - accuracy: 0.9819Epoch 1/40\n",
      "314/314 [==============================] - 262s 836ms/step - loss: 1.9611 - accuracy: 0.9819 - val_loss: 22.4934 - val_accuracy: 0.6546\n",
      "Epoch 17/40\n",
      "313/314 [============================>.] - ETA: 0s - loss: 1.9267 - accuracy: 0.9823Epoch 1/40\n",
      "314/314 [==============================] - 264s 842ms/step - loss: 1.9301 - accuracy: 0.9822 - val_loss: 22.5650 - val_accuracy: 0.6506\n",
      "Epoch 18/40\n",
      "313/314 [============================>.] - ETA: 0s - loss: 1.9049 - accuracy: 0.9825Epoch 1/40\n",
      "314/314 [==============================] - 262s 835ms/step - loss: 1.9026 - accuracy: 0.9825 - val_loss: 22.5996 - val_accuracy: 0.6470\n",
      "Epoch 19/40\n",
      "313/314 [============================>.] - ETA: 0s - loss: 1.8590 - accuracy: 0.9830Epoch 1/40\n",
      "314/314 [==============================] - 262s 835ms/step - loss: 1.8604 - accuracy: 0.9830 - val_loss: 22.5585 - val_accuracy: 0.6454\n",
      "Epoch 20/40\n",
      "313/314 [============================>.] - ETA: 0s - loss: 1.8293 - accuracy: 0.9834Epoch 1/40\n",
      "314/314 [==============================] - 262s 835ms/step - loss: 1.8297 - accuracy: 0.9834 - val_loss: 22.2398 - val_accuracy: 0.6482\n",
      "Epoch 21/40\n",
      "313/314 [============================>.] - ETA: 0s - loss: 1.8065 - accuracy: 0.9835Epoch 1/40\n",
      "314/314 [==============================] - 262s 835ms/step - loss: 1.8062 - accuracy: 0.9835 - val_loss: 22.1870 - val_accuracy: 0.6421\n",
      "Epoch 22/40\n",
      "313/314 [============================>.] - ETA: 0s - loss: 1.7832 - accuracy: 0.9838Epoch 1/40\n",
      "314/314 [==============================] - 262s 835ms/step - loss: 1.7848 - accuracy: 0.9838 - val_loss: 22.1582 - val_accuracy: 0.6305\n",
      "Epoch 23/40\n",
      "313/314 [============================>.] - ETA: 0s - loss: 1.7659 - accuracy: 0.9840Epoch 1/40\n",
      "314/314 [==============================] - 262s 835ms/step - loss: 1.7725 - accuracy: 0.9840 - val_loss: 21.9392 - val_accuracy: 0.6361\n",
      "Epoch 24/40\n",
      "313/314 [============================>.] - ETA: 0s - loss: 1.7445 - accuracy: 0.9841Epoch 1/40\n",
      "314/314 [==============================] - 263s 838ms/step - loss: 1.7476 - accuracy: 0.9840 - val_loss: 21.7053 - val_accuracy: 0.6301\n",
      "Epoch 25/40\n",
      "313/314 [============================>.] - ETA: 0s - loss: 1.7099 - accuracy: 0.9845Epoch 1/40\n",
      "314/314 [==============================] - 262s 835ms/step - loss: 1.7100 - accuracy: 0.9845 - val_loss: 21.8042 - val_accuracy: 0.6269\n",
      "Epoch 26/40\n",
      "313/314 [============================>.] - ETA: 0s - loss: 1.6890 - accuracy: 0.9848Epoch 1/40\n",
      "314/314 [==============================] - 262s 834ms/step - loss: 1.6914 - accuracy: 0.9848 - val_loss: 21.6086 - val_accuracy: 0.6235\n",
      "Epoch 27/40\n",
      "313/314 [============================>.] - ETA: 0s - loss: 1.6637 - accuracy: 0.9851Epoch 1/40\n",
      "314/314 [==============================] - 262s 834ms/step - loss: 1.6618 - accuracy: 0.9851 - val_loss: 21.5718 - val_accuracy: 0.6171\n",
      "Epoch 28/40\n",
      "313/314 [============================>.] - ETA: 0s - loss: 1.6553 - accuracy: 0.9852Epoch 1/40\n",
      "314/314 [==============================] - 262s 835ms/step - loss: 1.6537 - accuracy: 0.9852 - val_loss: 21.7057 - val_accuracy: 0.6158\n",
      "Epoch 29/40\n",
      "313/314 [============================>.] - ETA: 0s - loss: 1.6214 - accuracy: 0.9854Epoch 1/40\n",
      "314/314 [==============================] - 262s 834ms/step - loss: 1.6201 - accuracy: 0.9854 - val_loss: 21.6450 - val_accuracy: 0.6187\n",
      "Epoch 30/40\n",
      "313/314 [============================>.] - ETA: 0s - loss: 1.6184 - accuracy: 0.9857Epoch 1/40\n",
      "314/314 [==============================] - 262s 836ms/step - loss: 1.6171 - accuracy: 0.9857 - val_loss: 21.6206 - val_accuracy: 0.6182\n",
      "Epoch 31/40\n",
      "313/314 [============================>.] - ETA: 0s - loss: 1.5897 - accuracy: 0.9858Epoch 1/40\n",
      "314/314 [==============================] - 264s 840ms/step - loss: 1.5912 - accuracy: 0.9857 - val_loss: 21.4982 - val_accuracy: 0.6092\n",
      "Epoch 32/40\n",
      "313/314 [============================>.] - ETA: 0s - loss: 1.5633 - accuracy: 0.9861Epoch 1/40\n",
      "314/314 [==============================] - 263s 836ms/step - loss: 1.5621 - accuracy: 0.9861 - val_loss: 21.7093 - val_accuracy: 0.5982\n",
      "Epoch 33/40\n",
      "313/314 [============================>.] - ETA: 0s - loss: 1.5787 - accuracy: 0.9859Epoch 1/40\n",
      "314/314 [==============================] - 264s 842ms/step - loss: 1.5802 - accuracy: 0.9859 - val_loss: 21.3270 - val_accuracy: 0.5807\n",
      "Epoch 34/40\n",
      "313/314 [============================>.] - ETA: 0s - loss: 1.5568 - accuracy: 0.9861Epoch 1/40\n",
      "314/314 [==============================] - 265s 844ms/step - loss: 1.5554 - accuracy: 0.9861 - val_loss: 21.4236 - val_accuracy: 0.5864\n",
      "Epoch 35/40\n",
      "313/314 [============================>.] - ETA: 0s - loss: 1.5508 - accuracy: 0.9862Epoch 1/40\n",
      "314/314 [==============================] - 270s 859ms/step - loss: 1.5525 - accuracy: 0.9862 - val_loss: 21.3994 - val_accuracy: 0.5823\n",
      "Epoch 36/40\n",
      "313/314 [============================>.] - ETA: 0s - loss: 1.5199 - accuracy: 0.9864Epoch 1/40\n",
      "314/314 [==============================] - 263s 837ms/step - loss: 1.5191 - accuracy: 0.9864 - val_loss: 21.3966 - val_accuracy: 0.5697\n",
      "Epoch 37/40\n",
      "313/314 [============================>.] - ETA: 0s - loss: 1.4893 - accuracy: 0.9868Epoch 1/40\n",
      "314/314 [==============================] - 263s 837ms/step - loss: 1.4923 - accuracy: 0.9868 - val_loss: 21.2760 - val_accuracy: 0.5718\n",
      "Epoch 38/40\n",
      "313/314 [============================>.] - ETA: 0s - loss: 1.4879 - accuracy: 0.9869Epoch 1/40\n",
      "314/314 [==============================] - 272s 866ms/step - loss: 1.4896 - accuracy: 0.9869 - val_loss: 21.2394 - val_accuracy: 0.5738\n",
      "Epoch 39/40\n",
      "313/314 [============================>.] - ETA: 0s - loss: 1.4835 - accuracy: 0.9869Epoch 1/40\n",
      "314/314 [==============================] - 264s 840ms/step - loss: 1.4851 - accuracy: 0.9869 - val_loss: 21.4823 - val_accuracy: 0.5685\n",
      "Epoch 40/40\n",
      "313/314 [============================>.] - ETA: 0s - loss: 1.4615 - accuracy: 0.9870Epoch 1/40\n",
      "314/314 [==============================] - 263s 839ms/step - loss: 1.4619 - accuracy: 0.9870 - val_loss: 21.0283 - val_accuracy: 0.5688\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27c9a27eba8>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BiLSTM_CRF_Model(bert_embed)\n",
    "#valid_x, valid_y = trainx[:250], trainy[:250]\n",
    "model.fit(store_data_trainx, store_data_trainy, store_data_devx, store_data_devy,epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           precision    recall  f1-score   support\n",
      "\n",
      "        B     0.7792    0.6781    0.7252     31241\n",
      "\n",
      "micro avg     0.7791    0.6781    0.7251     31241\n",
      "macro avg     0.7792    0.6781    0.7252     31241\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'           precision    recall  f1-score   support\\n\\n        B     0.7792    0.6781    0.7252     31241\\n\\nmicro avg     0.7791    0.6781    0.7251     31241\\nmacro avg     0.7792    0.6781    0.7252     31241\\n'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 验证模型，此方法将打印出详细的验证报告  10\n",
    "model.evaluate(store_data_testx, store_data_testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"mymodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Sequence length will auto set at 95% of sequence length\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 50)]              0         \n",
      "_________________________________________________________________\n",
      "layer_embedding (Embedding)  (None, 50, 100)           1101800   \n",
      "_________________________________________________________________\n",
      "layer_blstm (Bidirectional)  (None, 50, 256)           235520    \n",
      "_________________________________________________________________\n",
      "layer_dense (Dense)          (None, 50, 64)            16448     \n",
      "_________________________________________________________________\n",
      "layer_crf_dense (Dense)      (None, 50, 3)             195       \n",
      "_________________________________________________________________\n",
      "layer_crf (CRF)              (None, 50, 3)             9         \n",
      "=================================================================\n",
      "Total params: 1,353,972\n",
      "Trainable params: 1,353,972\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "313/314 [============================>.] - ETA: 0s - loss: 7.0186 - accuracy: 0.9504Epoch 1/3\n",
      "314/314 [==============================] - 44s 141ms/step - loss: 7.0159 - accuracy: 0.9504 - val_loss: 46.8170 - val_accuracy: 0.7760\n",
      "Epoch 2/3\n",
      "313/314 [============================>.] - ETA: 0s - loss: 1.8009 - accuracy: 0.9872Epoch 1/3\n",
      "314/314 [==============================] - 42s 133ms/step - loss: 1.7969 - accuracy: 0.9872 - val_loss: 46.7186 - val_accuracy: 0.7706\n",
      "Epoch 3/3\n",
      "313/314 [============================>.] - ETA: 0s - loss: 1.4504 - accuracy: 0.9891Epoch 1/3\n",
      "314/314 [==============================] - 41s 132ms/step - loss: 1.4471 - accuracy: 0.9891 - val_loss: 46.3656 - val_accuracy: 0.7747\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1faae52d518>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BiLSTM_CRF_Model()\n",
    "#valid_x, valid_y = trainx[:250], trainy[:250]\n",
    "model.fit(store_data_trainx, store_data_trainy, store_data_devx, store_data_devy,epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           precision    recall  f1-score   support\n",
      "\n",
      "        B     0.8804    0.6536    0.7503     31293\n",
      "\n",
      "micro avg     0.8802    0.6536    0.7502     31293\n",
      "macro avg     0.8804    0.6536    0.7503     31293\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'           precision    recall  f1-score   support\\n\\n        B     0.8804    0.6536    0.7503     31293\\n\\nmicro avg     0.8802    0.6536    0.7502     31293\\nmacro avg     0.8804    0.6536    0.7503     31293\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 验证模型，此方法将打印出详细的验证报告 BiLSTM_CRF_Model  3\n",
    "model.evaluate(store_data_testx, store_data_testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#3\n",
    "micro avg     0.8883    0.6406    0.7444     31293\n",
    "macro avg     0.8887    0.6406    0.7445     31293"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input-Token (InputLayer)        [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Input-Segment (InputLayer)      [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token (TokenEmbedding [(None, 50, 1024), ( 60411904    Input-Token[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Segment (Embedding)   (None, 50, 1024)     2048        Input-Segment[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token-Segment (Add)   (None, 50, 1024)     0           Embedding-Token[0][0]            \n",
      "                                                                 Embedding-Segment[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Position (PositionEmb (None, 50, 1024)     51200       Embedding-Token-Segment[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Dropout (Dropout)     (None, 50, 1024)     0           Embedding-Position[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Norm (LayerNormalizat (None, 50, 1024)     2048        Embedding-Dropout[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 50, 1024)     4198400     Embedding-Norm[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 50, 1024)     0           Encoder-1-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 50, 1024)     0           Embedding-Norm[0][0]             \n",
      "                                                                 Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 50, 1024)     2048        Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward (FeedForw (None, 50, 1024)     8393728     Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Dropout ( (None, 50, 1024)     0           Encoder-1-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Add (Add) (None, 50, 1024)     0           Encoder-1-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-1-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Norm (Lay (None, 50, 1024)     2048        Encoder-1-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 50, 1024)     4198400     Encoder-1-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 50, 1024)     0           Encoder-2-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 50, 1024)     0           Encoder-1-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 50, 1024)     2048        Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward (FeedForw (None, 50, 1024)     8393728     Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Dropout ( (None, 50, 1024)     0           Encoder-2-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Add (Add) (None, 50, 1024)     0           Encoder-2-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-2-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Norm (Lay (None, 50, 1024)     2048        Encoder-2-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 50, 1024)     4198400     Encoder-2-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 50, 1024)     0           Encoder-3-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 50, 1024)     0           Encoder-2-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 50, 1024)     2048        Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward (FeedForw (None, 50, 1024)     8393728     Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Dropout ( (None, 50, 1024)     0           Encoder-3-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Add (Add) (None, 50, 1024)     0           Encoder-3-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-3-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Norm (Lay (None, 50, 1024)     2048        Encoder-3-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 50, 1024)     4198400     Encoder-3-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 50, 1024)     0           Encoder-4-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 50, 1024)     0           Encoder-3-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 50, 1024)     2048        Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward (FeedForw (None, 50, 1024)     8393728     Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Dropout ( (None, 50, 1024)     0           Encoder-4-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Add (Add) (None, 50, 1024)     0           Encoder-4-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-4-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Norm (Lay (None, 50, 1024)     2048        Encoder-4-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 50, 1024)     4198400     Encoder-4-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 50, 1024)     0           Encoder-5-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 50, 1024)     0           Encoder-4-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 50, 1024)     2048        Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward (FeedForw (None, 50, 1024)     8393728     Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Dropout ( (None, 50, 1024)     0           Encoder-5-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Add (Add) (None, 50, 1024)     0           Encoder-5-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-5-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Norm (Lay (None, 50, 1024)     2048        Encoder-5-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 50, 1024)     4198400     Encoder-5-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 50, 1024)     0           Encoder-6-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 50, 1024)     0           Encoder-5-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 50, 1024)     2048        Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward (FeedForw (None, 50, 1024)     8393728     Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Dropout ( (None, 50, 1024)     0           Encoder-6-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Add (Add) (None, 50, 1024)     0           Encoder-6-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-6-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Norm (Lay (None, 50, 1024)     2048        Encoder-6-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 50, 1024)     4198400     Encoder-6-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 50, 1024)     0           Encoder-7-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 50, 1024)     0           Encoder-6-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 50, 1024)     2048        Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward (FeedForw (None, 50, 1024)     8393728     Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Dropout ( (None, 50, 1024)     0           Encoder-7-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Add (Add) (None, 50, 1024)     0           Encoder-7-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-7-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Norm (Lay (None, 50, 1024)     2048        Encoder-7-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 50, 1024)     4198400     Encoder-7-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 50, 1024)     0           Encoder-8-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 50, 1024)     0           Encoder-7-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 50, 1024)     2048        Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward (FeedForw (None, 50, 1024)     8393728     Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Dropout ( (None, 50, 1024)     0           Encoder-8-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Add (Add) (None, 50, 1024)     0           Encoder-8-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-8-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Norm (Lay (None, 50, 1024)     2048        Encoder-8-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 50, 1024)     4198400     Encoder-8-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 50, 1024)     0           Encoder-9-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 50, 1024)     0           Encoder-8-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 50, 1024)     2048        Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward (FeedForw (None, 50, 1024)     8393728     Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Dropout ( (None, 50, 1024)     0           Encoder-9-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Add (Add) (None, 50, 1024)     0           Encoder-9-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-9-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Norm (Lay (None, 50, 1024)     2048        Encoder-9-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 50, 1024)     4198400     Encoder-9-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-9-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 50, 1024)     2048        Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward (FeedFor (None, 50, 1024)     8393728     Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Dropout  (None, 50, 1024)     0           Encoder-10-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Add (Add (None, 50, 1024)     0           Encoder-10-MultiHeadSelfAttention\n",
      "                                                                 Encoder-10-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Norm (La (None, 50, 1024)     2048        Encoder-10-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 50, 1024)     4198400     Encoder-10-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-10-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 50, 1024)     2048        Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward (FeedFor (None, 50, 1024)     8393728     Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Dropout  (None, 50, 1024)     0           Encoder-11-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Add (Add (None, 50, 1024)     0           Encoder-11-MultiHeadSelfAttention\n",
      "                                                                 Encoder-11-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Norm (La (None, 50, 1024)     2048        Encoder-11-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 50, 1024)     4198400     Encoder-11-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-11-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 50, 1024)     2048        Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward (FeedFor (None, 50, 1024)     8393728     Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Dropout  (None, 50, 1024)     0           Encoder-12-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Add (Add (None, 50, 1024)     0           Encoder-12-MultiHeadSelfAttention\n",
      "                                                                 Encoder-12-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Norm (La (None, 50, 1024)     2048        Encoder-12-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-13-MultiHeadSelfAttenti (None, 50, 1024)     4198400     Encoder-12-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-13-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-13-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-13-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-12-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-13-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-13-MultiHeadSelfAttenti (None, 50, 1024)     2048        Encoder-13-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-13-FeedForward (FeedFor (None, 50, 1024)     8393728     Encoder-13-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-13-FeedForward-Dropout  (None, 50, 1024)     0           Encoder-13-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-13-FeedForward-Add (Add (None, 50, 1024)     0           Encoder-13-MultiHeadSelfAttention\n",
      "                                                                 Encoder-13-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-13-FeedForward-Norm (La (None, 50, 1024)     2048        Encoder-13-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-14-MultiHeadSelfAttenti (None, 50, 1024)     4198400     Encoder-13-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-14-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-14-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-14-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-13-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-14-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-14-MultiHeadSelfAttenti (None, 50, 1024)     2048        Encoder-14-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-14-FeedForward (FeedFor (None, 50, 1024)     8393728     Encoder-14-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-14-FeedForward-Dropout  (None, 50, 1024)     0           Encoder-14-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-14-FeedForward-Add (Add (None, 50, 1024)     0           Encoder-14-MultiHeadSelfAttention\n",
      "                                                                 Encoder-14-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-14-FeedForward-Norm (La (None, 50, 1024)     2048        Encoder-14-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-15-MultiHeadSelfAttenti (None, 50, 1024)     4198400     Encoder-14-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-15-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-15-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-15-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-14-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-15-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-15-MultiHeadSelfAttenti (None, 50, 1024)     2048        Encoder-15-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-15-FeedForward (FeedFor (None, 50, 1024)     8393728     Encoder-15-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-15-FeedForward-Dropout  (None, 50, 1024)     0           Encoder-15-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-15-FeedForward-Add (Add (None, 50, 1024)     0           Encoder-15-MultiHeadSelfAttention\n",
      "                                                                 Encoder-15-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-15-FeedForward-Norm (La (None, 50, 1024)     2048        Encoder-15-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-16-MultiHeadSelfAttenti (None, 50, 1024)     4198400     Encoder-15-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-16-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-16-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-16-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-15-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-16-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-16-MultiHeadSelfAttenti (None, 50, 1024)     2048        Encoder-16-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-16-FeedForward (FeedFor (None, 50, 1024)     8393728     Encoder-16-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-16-FeedForward-Dropout  (None, 50, 1024)     0           Encoder-16-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-16-FeedForward-Add (Add (None, 50, 1024)     0           Encoder-16-MultiHeadSelfAttention\n",
      "                                                                 Encoder-16-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-16-FeedForward-Norm (La (None, 50, 1024)     2048        Encoder-16-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-17-MultiHeadSelfAttenti (None, 50, 1024)     4198400     Encoder-16-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-17-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-17-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-17-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-16-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-17-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-17-MultiHeadSelfAttenti (None, 50, 1024)     2048        Encoder-17-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-17-FeedForward (FeedFor (None, 50, 1024)     8393728     Encoder-17-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-17-FeedForward-Dropout  (None, 50, 1024)     0           Encoder-17-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-17-FeedForward-Add (Add (None, 50, 1024)     0           Encoder-17-MultiHeadSelfAttention\n",
      "                                                                 Encoder-17-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-17-FeedForward-Norm (La (None, 50, 1024)     2048        Encoder-17-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-18-MultiHeadSelfAttenti (None, 50, 1024)     4198400     Encoder-17-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-18-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-18-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-18-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-17-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-18-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-18-MultiHeadSelfAttenti (None, 50, 1024)     2048        Encoder-18-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-18-FeedForward (FeedFor (None, 50, 1024)     8393728     Encoder-18-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-18-FeedForward-Dropout  (None, 50, 1024)     0           Encoder-18-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-18-FeedForward-Add (Add (None, 50, 1024)     0           Encoder-18-MultiHeadSelfAttention\n",
      "                                                                 Encoder-18-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-18-FeedForward-Norm (La (None, 50, 1024)     2048        Encoder-18-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-19-MultiHeadSelfAttenti (None, 50, 1024)     4198400     Encoder-18-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-19-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-19-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-19-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-18-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-19-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-19-MultiHeadSelfAttenti (None, 50, 1024)     2048        Encoder-19-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-19-FeedForward (FeedFor (None, 50, 1024)     8393728     Encoder-19-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-19-FeedForward-Dropout  (None, 50, 1024)     0           Encoder-19-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-19-FeedForward-Add (Add (None, 50, 1024)     0           Encoder-19-MultiHeadSelfAttention\n",
      "                                                                 Encoder-19-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-19-FeedForward-Norm (La (None, 50, 1024)     2048        Encoder-19-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-20-MultiHeadSelfAttenti (None, 50, 1024)     4198400     Encoder-19-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-20-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-20-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-20-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-19-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-20-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-20-MultiHeadSelfAttenti (None, 50, 1024)     2048        Encoder-20-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-20-FeedForward (FeedFor (None, 50, 1024)     8393728     Encoder-20-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-20-FeedForward-Dropout  (None, 50, 1024)     0           Encoder-20-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-20-FeedForward-Add (Add (None, 50, 1024)     0           Encoder-20-MultiHeadSelfAttention\n",
      "                                                                 Encoder-20-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-20-FeedForward-Norm (La (None, 50, 1024)     2048        Encoder-20-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-21-MultiHeadSelfAttenti (None, 50, 1024)     4198400     Encoder-20-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-21-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-21-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-21-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-20-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-21-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-21-MultiHeadSelfAttenti (None, 50, 1024)     2048        Encoder-21-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-21-FeedForward (FeedFor (None, 50, 1024)     8393728     Encoder-21-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-21-FeedForward-Dropout  (None, 50, 1024)     0           Encoder-21-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-21-FeedForward-Add (Add (None, 50, 1024)     0           Encoder-21-MultiHeadSelfAttention\n",
      "                                                                 Encoder-21-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-21-FeedForward-Norm (La (None, 50, 1024)     2048        Encoder-21-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-22-MultiHeadSelfAttenti (None, 50, 1024)     4198400     Encoder-21-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-22-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-22-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-22-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-21-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-22-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-22-MultiHeadSelfAttenti (None, 50, 1024)     2048        Encoder-22-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-22-FeedForward (FeedFor (None, 50, 1024)     8393728     Encoder-22-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-22-FeedForward-Dropout  (None, 50, 1024)     0           Encoder-22-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-22-FeedForward-Add (Add (None, 50, 1024)     0           Encoder-22-MultiHeadSelfAttention\n",
      "                                                                 Encoder-22-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-22-FeedForward-Norm (La (None, 50, 1024)     2048        Encoder-22-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-23-MultiHeadSelfAttenti (None, 50, 1024)     4198400     Encoder-22-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-23-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-23-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-23-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-22-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-23-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-23-MultiHeadSelfAttenti (None, 50, 1024)     2048        Encoder-23-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-23-FeedForward (FeedFor (None, 50, 1024)     8393728     Encoder-23-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-23-FeedForward-Dropout  (None, 50, 1024)     0           Encoder-23-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-23-FeedForward-Add (Add (None, 50, 1024)     0           Encoder-23-MultiHeadSelfAttention\n",
      "                                                                 Encoder-23-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-23-FeedForward-Norm (La (None, 50, 1024)     2048        Encoder-23-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-24-MultiHeadSelfAttenti (None, 50, 1024)     4198400     Encoder-23-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-24-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-24-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-24-MultiHeadSelfAttenti (None, 50, 1024)     0           Encoder-23-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-24-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-24-MultiHeadSelfAttenti (None, 50, 1024)     2048        Encoder-24-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-24-FeedForward (FeedFor (None, 50, 1024)     8393728     Encoder-24-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-24-FeedForward-Dropout  (None, 50, 1024)     0           Encoder-24-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-24-FeedForward-Add (Add (None, 50, 1024)     0           Encoder-24-MultiHeadSelfAttention\n",
      "                                                                 Encoder-24-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-24-FeedForward-Norm (La (None, 50, 1024)     2048        Encoder-24-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Output (Concatenate)    (None, 50, 4096)     0           Encoder-21-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-22-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-23-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-24-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "non_masking_layer (NonMaskingLa (None, 50, 4096)     0           Encoder-Output[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_blstm (Bidirectional)     (None, 50, 256)      4327424     non_masking_layer[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "layer_dense (Dense)             (None, 50, 64)       16448       layer_blstm[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "layer_crf_dense (Dense)         (None, 50, 3)        195         layer_dense[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "layer_crf (CRF)                 (None, 50, 3)        9           layer_crf_dense[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 367,120,652\n",
      "Trainable params: 4,344,076\n",
      "Non-trainable params: 362,776,576\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "313/314 [============================>.] - ETA: 0s - loss: 4.6254 - accuracy: 0.9572Epoch 1/10\n",
      "314/314 [==============================] - 268s 855ms/step - loss: 4.6245 - accuracy: 0.9572 - val_loss: 37.4303 - val_accuracy: 0.6751\n",
      "Epoch 2/10\n",
      "313/314 [============================>.] - ETA: 0s - loss: 3.2555 - accuracy: 0.9686Epoch 1/10\n",
      "314/314 [==============================] - 260s 829ms/step - loss: 3.2577 - accuracy: 0.9686 - val_loss: 37.2014 - val_accuracy: 0.6743\n",
      "Epoch 3/10\n",
      "313/314 [============================>.] - ETA: 0s - loss: 2.9991 - accuracy: 0.9711Epoch 1/10\n",
      "314/314 [==============================] - 263s 837ms/step - loss: 2.9952 - accuracy: 0.9711 - val_loss: 37.0037 - val_accuracy: 0.6760\n",
      "Epoch 4/10\n",
      "313/314 [============================>.] - ETA: 0s - loss: 2.8310 - accuracy: 0.9727Epoch 1/10\n",
      "314/314 [==============================] - 261s 832ms/step - loss: 2.8334 - accuracy: 0.9727 - val_loss: 36.8267 - val_accuracy: 0.6844\n",
      "Epoch 5/10\n",
      "313/314 [============================>.] - ETA: 0s - loss: 2.6954 - accuracy: 0.9741Epoch 1/10\n",
      "314/314 [==============================] - 261s 832ms/step - loss: 2.6948 - accuracy: 0.9741 - val_loss: 36.6618 - val_accuracy: 0.6858\n",
      "Epoch 6/10\n",
      "313/314 [============================>.] - ETA: 0s - loss: 2.5790 - accuracy: 0.9752Epoch 1/10\n",
      "314/314 [==============================] - 261s 833ms/step - loss: 2.5778 - accuracy: 0.9752 - val_loss: 36.7249 - val_accuracy: 0.6856\n",
      "Epoch 7/10\n",
      "313/314 [============================>.] - ETA: 0s - loss: 2.5048 - accuracy: 0.9759Epoch 1/10\n",
      "314/314 [==============================] - 262s 833ms/step - loss: 2.5017 - accuracy: 0.9759 - val_loss: 36.7893 - val_accuracy: 0.6835\n",
      "Epoch 8/10\n",
      "313/314 [============================>.] - ETA: 0s - loss: 2.4244 - accuracy: 0.9769Epoch 1/10\n",
      "314/314 [==============================] - 262s 835ms/step - loss: 2.4256 - accuracy: 0.9769 - val_loss: 36.2884 - val_accuracy: 0.6882\n",
      "Epoch 9/10\n",
      "313/314 [============================>.] - ETA: 0s - loss: 2.3523 - accuracy: 0.9775Epoch 1/10\n",
      "314/314 [==============================] - 262s 833ms/step - loss: 2.3513 - accuracy: 0.9775 - val_loss: 36.2022 - val_accuracy: 0.6855\n",
      "Epoch 10/10\n",
      "313/314 [============================>.] - ETA: 0s - loss: 2.2892 - accuracy: 0.9783Epoch 1/10\n",
      "314/314 [==============================] - 264s 841ms/step - loss: 2.2853 - accuracy: 0.9783 - val_loss: 36.3001 - val_accuracy: 0.6841\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1faab69fc88>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BiLSTM_CRF_Model(bert_embed)\n",
    "#valid_x, valid_y = trainx[:250], trainy[:250]\n",
    "model.fit(store_data_trainx, store_data_trainy, store_data_devx, store_data_devy,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           precision    recall  f1-score   support\n",
      "\n",
      "        B     0.7583    0.7285    0.7431     31241\n",
      "\n",
      "micro avg     0.7582    0.7285    0.7430     31241\n",
      "macro avg     0.7583    0.7285    0.7431     31241\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'           precision    recall  f1-score   support\\n\\n        B     0.7583    0.7285    0.7431     31241\\n\\nmicro avg     0.7582    0.7285    0.7430     31241\\nmacro avg     0.7583    0.7285    0.7431     31241\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 验证模型，此方法将打印出详细的验证报告 BiLSTM_CRF_Model(bert_embed)  3\n",
    "model.evaluate(store_data_testx, store_data_testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10  bert\n",
    "\n",
    "micro avg     0.7251    0.7072    0.7161     31793\n",
    "macro avg     0.7251    0.7072    0.7161     31793\n",
    "\n",
    "\n",
    "# biobert 10   30 sqence\n",
    "micro avg     0.7827    0.7144    0.7470     27732\n",
    "macro avg     0.7827    0.7144    0.7470     27732\n",
    "\n",
    "#biobert 10  auto   95% length of sqence\n",
    "micro avg     0.7542    0.7699    0.7620     31241\n",
    "macro avg     0.7542    0.7699    0.7620     31241\n",
    "\n",
    "#biobert 40  auto   95% length of sqence   crf\n",
    "micro avg     0.7791    0.6781    0.7251     31241\n",
    "macro avg     0.7792    0.6781    0.7252     31241\n",
    "\n",
    "micro avg     0.8068    0.7286    0.7657     31293\n",
    "macro avg     0.8068    0.7286    0.7657     31293\n",
    "\n",
    "\n",
    "\n",
    "#biobert 3  auto   95% length of sqence   crf  bert\n",
    "micro avg     0.7259    0.7796    0.7518     31241\n",
    "macro avg     0.7260    0.7796    0.7518     31241\n",
    "\n",
    "10\n",
    "micro avg     0.7582    0.7285    0.7430     31241\n",
    "macro avg     0.7583    0.7285    0.7431     31241"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input-Token (InputLayer)        [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Input-Segment (InputLayer)      [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token (TokenEmbedding [(None, 100, 1024),  29691904    Input-Token[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Segment (Embedding)   (None, 100, 1024)    2048        Input-Segment[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token-Segment (Add)   (None, 100, 1024)    0           Embedding-Token[0][0]            \n",
      "                                                                 Embedding-Segment[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Position (PositionEmb (None, 100, 1024)    102400      Embedding-Token-Segment[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Dropout (Dropout)     (None, 100, 1024)    0           Embedding-Position[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Norm (LayerNormalizat (None, 100, 1024)    2048        Embedding-Dropout[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 100, 1024)    4198400     Embedding-Norm[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 100, 1024)    0           Encoder-1-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 100, 1024)    0           Embedding-Norm[0][0]             \n",
      "                                                                 Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 100, 1024)    2048        Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward (FeedForw (None, 100, 1024)    8393728     Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Dropout ( (None, 100, 1024)    0           Encoder-1-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Add (Add) (None, 100, 1024)    0           Encoder-1-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-1-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Norm (Lay (None, 100, 1024)    2048        Encoder-1-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 100, 1024)    4198400     Encoder-1-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 100, 1024)    0           Encoder-2-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 100, 1024)    0           Encoder-1-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 100, 1024)    2048        Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward (FeedForw (None, 100, 1024)    8393728     Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Dropout ( (None, 100, 1024)    0           Encoder-2-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Add (Add) (None, 100, 1024)    0           Encoder-2-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-2-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Norm (Lay (None, 100, 1024)    2048        Encoder-2-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 100, 1024)    4198400     Encoder-2-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 100, 1024)    0           Encoder-3-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 100, 1024)    0           Encoder-2-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 100, 1024)    2048        Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward (FeedForw (None, 100, 1024)    8393728     Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Dropout ( (None, 100, 1024)    0           Encoder-3-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Add (Add) (None, 100, 1024)    0           Encoder-3-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-3-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Norm (Lay (None, 100, 1024)    2048        Encoder-3-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 100, 1024)    4198400     Encoder-3-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 100, 1024)    0           Encoder-4-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 100, 1024)    0           Encoder-3-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 100, 1024)    2048        Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward (FeedForw (None, 100, 1024)    8393728     Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Dropout ( (None, 100, 1024)    0           Encoder-4-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Add (Add) (None, 100, 1024)    0           Encoder-4-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-4-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Norm (Lay (None, 100, 1024)    2048        Encoder-4-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 100, 1024)    4198400     Encoder-4-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 100, 1024)    0           Encoder-5-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 100, 1024)    0           Encoder-4-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 100, 1024)    2048        Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward (FeedForw (None, 100, 1024)    8393728     Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Dropout ( (None, 100, 1024)    0           Encoder-5-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Add (Add) (None, 100, 1024)    0           Encoder-5-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-5-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Norm (Lay (None, 100, 1024)    2048        Encoder-5-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 100, 1024)    4198400     Encoder-5-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 100, 1024)    0           Encoder-6-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 100, 1024)    0           Encoder-5-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 100, 1024)    2048        Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward (FeedForw (None, 100, 1024)    8393728     Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Dropout ( (None, 100, 1024)    0           Encoder-6-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Add (Add) (None, 100, 1024)    0           Encoder-6-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-6-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Norm (Lay (None, 100, 1024)    2048        Encoder-6-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 100, 1024)    4198400     Encoder-6-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 100, 1024)    0           Encoder-7-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 100, 1024)    0           Encoder-6-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 100, 1024)    2048        Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward (FeedForw (None, 100, 1024)    8393728     Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Dropout ( (None, 100, 1024)    0           Encoder-7-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Add (Add) (None, 100, 1024)    0           Encoder-7-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-7-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Norm (Lay (None, 100, 1024)    2048        Encoder-7-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 100, 1024)    4198400     Encoder-7-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 100, 1024)    0           Encoder-8-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 100, 1024)    0           Encoder-7-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 100, 1024)    2048        Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward (FeedForw (None, 100, 1024)    8393728     Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Dropout ( (None, 100, 1024)    0           Encoder-8-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Add (Add) (None, 100, 1024)    0           Encoder-8-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-8-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Norm (Lay (None, 100, 1024)    2048        Encoder-8-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 100, 1024)    4198400     Encoder-8-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 100, 1024)    0           Encoder-9-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 100, 1024)    0           Encoder-8-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 100, 1024)    2048        Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward (FeedForw (None, 100, 1024)    8393728     Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Dropout ( (None, 100, 1024)    0           Encoder-9-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Add (Add) (None, 100, 1024)    0           Encoder-9-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-9-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Norm (Lay (None, 100, 1024)    2048        Encoder-9-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 100, 1024)    4198400     Encoder-9-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 100, 1024)    0           Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 100, 1024)    0           Encoder-9-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 100, 1024)    2048        Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward (FeedFor (None, 100, 1024)    8393728     Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Dropout  (None, 100, 1024)    0           Encoder-10-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Add (Add (None, 100, 1024)    0           Encoder-10-MultiHeadSelfAttention\n",
      "                                                                 Encoder-10-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Norm (La (None, 100, 1024)    2048        Encoder-10-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 100, 1024)    4198400     Encoder-10-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 100, 1024)    0           Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 100, 1024)    0           Encoder-10-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 100, 1024)    2048        Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward (FeedFor (None, 100, 1024)    8393728     Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Dropout  (None, 100, 1024)    0           Encoder-11-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Add (Add (None, 100, 1024)    0           Encoder-11-MultiHeadSelfAttention\n",
      "                                                                 Encoder-11-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Norm (La (None, 100, 1024)    2048        Encoder-11-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 100, 1024)    4198400     Encoder-11-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 100, 1024)    0           Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 100, 1024)    0           Encoder-11-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 100, 1024)    2048        Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward (FeedFor (None, 100, 1024)    8393728     Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Dropout  (None, 100, 1024)    0           Encoder-12-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Add (Add (None, 100, 1024)    0           Encoder-12-MultiHeadSelfAttention\n",
      "                                                                 Encoder-12-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Norm (La (None, 100, 1024)    2048        Encoder-12-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-13-MultiHeadSelfAttenti (None, 100, 1024)    4198400     Encoder-12-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-13-MultiHeadSelfAttenti (None, 100, 1024)    0           Encoder-13-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-13-MultiHeadSelfAttenti (None, 100, 1024)    0           Encoder-12-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-13-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-13-MultiHeadSelfAttenti (None, 100, 1024)    2048        Encoder-13-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-13-FeedForward (FeedFor (None, 100, 1024)    8393728     Encoder-13-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-13-FeedForward-Dropout  (None, 100, 1024)    0           Encoder-13-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-13-FeedForward-Add (Add (None, 100, 1024)    0           Encoder-13-MultiHeadSelfAttention\n",
      "                                                                 Encoder-13-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-13-FeedForward-Norm (La (None, 100, 1024)    2048        Encoder-13-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-14-MultiHeadSelfAttenti (None, 100, 1024)    4198400     Encoder-13-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-14-MultiHeadSelfAttenti (None, 100, 1024)    0           Encoder-14-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-14-MultiHeadSelfAttenti (None, 100, 1024)    0           Encoder-13-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-14-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-14-MultiHeadSelfAttenti (None, 100, 1024)    2048        Encoder-14-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-14-FeedForward (FeedFor (None, 100, 1024)    8393728     Encoder-14-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-14-FeedForward-Dropout  (None, 100, 1024)    0           Encoder-14-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-14-FeedForward-Add (Add (None, 100, 1024)    0           Encoder-14-MultiHeadSelfAttention\n",
      "                                                                 Encoder-14-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-14-FeedForward-Norm (La (None, 100, 1024)    2048        Encoder-14-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-15-MultiHeadSelfAttenti (None, 100, 1024)    4198400     Encoder-14-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-15-MultiHeadSelfAttenti (None, 100, 1024)    0           Encoder-15-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-15-MultiHeadSelfAttenti (None, 100, 1024)    0           Encoder-14-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-15-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-15-MultiHeadSelfAttenti (None, 100, 1024)    2048        Encoder-15-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-15-FeedForward (FeedFor (None, 100, 1024)    8393728     Encoder-15-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-15-FeedForward-Dropout  (None, 100, 1024)    0           Encoder-15-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-15-FeedForward-Add (Add (None, 100, 1024)    0           Encoder-15-MultiHeadSelfAttention\n",
      "                                                                 Encoder-15-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-15-FeedForward-Norm (La (None, 100, 1024)    2048        Encoder-15-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-16-MultiHeadSelfAttenti (None, 100, 1024)    4198400     Encoder-15-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-16-MultiHeadSelfAttenti (None, 100, 1024)    0           Encoder-16-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-16-MultiHeadSelfAttenti (None, 100, 1024)    0           Encoder-15-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-16-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-16-MultiHeadSelfAttenti (None, 100, 1024)    2048        Encoder-16-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-16-FeedForward (FeedFor (None, 100, 1024)    8393728     Encoder-16-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-16-FeedForward-Dropout  (None, 100, 1024)    0           Encoder-16-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-16-FeedForward-Add (Add (None, 100, 1024)    0           Encoder-16-MultiHeadSelfAttention\n",
      "                                                                 Encoder-16-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-16-FeedForward-Norm (La (None, 100, 1024)    2048        Encoder-16-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-17-MultiHeadSelfAttenti (None, 100, 1024)    4198400     Encoder-16-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-17-MultiHeadSelfAttenti (None, 100, 1024)    0           Encoder-17-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-17-MultiHeadSelfAttenti (None, 100, 1024)    0           Encoder-16-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-17-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-17-MultiHeadSelfAttenti (None, 100, 1024)    2048        Encoder-17-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-17-FeedForward (FeedFor (None, 100, 1024)    8393728     Encoder-17-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-17-FeedForward-Dropout  (None, 100, 1024)    0           Encoder-17-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-17-FeedForward-Add (Add (None, 100, 1024)    0           Encoder-17-MultiHeadSelfAttention\n",
      "                                                                 Encoder-17-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-17-FeedForward-Norm (La (None, 100, 1024)    2048        Encoder-17-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-18-MultiHeadSelfAttenti (None, 100, 1024)    4198400     Encoder-17-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-18-MultiHeadSelfAttenti (None, 100, 1024)    0           Encoder-18-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-18-MultiHeadSelfAttenti (None, 100, 1024)    0           Encoder-17-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-18-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-18-MultiHeadSelfAttenti (None, 100, 1024)    2048        Encoder-18-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-18-FeedForward (FeedFor (None, 100, 1024)    8393728     Encoder-18-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-18-FeedForward-Dropout  (None, 100, 1024)    0           Encoder-18-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-18-FeedForward-Add (Add (None, 100, 1024)    0           Encoder-18-MultiHeadSelfAttention\n",
      "                                                                 Encoder-18-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-18-FeedForward-Norm (La (None, 100, 1024)    2048        Encoder-18-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-19-MultiHeadSelfAttenti (None, 100, 1024)    4198400     Encoder-18-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-19-MultiHeadSelfAttenti (None, 100, 1024)    0           Encoder-19-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-19-MultiHeadSelfAttenti (None, 100, 1024)    0           Encoder-18-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-19-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-19-MultiHeadSelfAttenti (None, 100, 1024)    2048        Encoder-19-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-19-FeedForward (FeedFor (None, 100, 1024)    8393728     Encoder-19-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-19-FeedForward-Dropout  (None, 100, 1024)    0           Encoder-19-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-19-FeedForward-Add (Add (None, 100, 1024)    0           Encoder-19-MultiHeadSelfAttention\n",
      "                                                                 Encoder-19-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-19-FeedForward-Norm (La (None, 100, 1024)    2048        Encoder-19-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-20-MultiHeadSelfAttenti (None, 100, 1024)    4198400     Encoder-19-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-20-MultiHeadSelfAttenti (None, 100, 1024)    0           Encoder-20-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-20-MultiHeadSelfAttenti (None, 100, 1024)    0           Encoder-19-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-20-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-20-MultiHeadSelfAttenti (None, 100, 1024)    2048        Encoder-20-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-20-FeedForward (FeedFor (None, 100, 1024)    8393728     Encoder-20-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-20-FeedForward-Dropout  (None, 100, 1024)    0           Encoder-20-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-20-FeedForward-Add (Add (None, 100, 1024)    0           Encoder-20-MultiHeadSelfAttention\n",
      "                                                                 Encoder-20-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-20-FeedForward-Norm (La (None, 100, 1024)    2048        Encoder-20-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-21-MultiHeadSelfAttenti (None, 100, 1024)    4198400     Encoder-20-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-21-MultiHeadSelfAttenti (None, 100, 1024)    0           Encoder-21-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-21-MultiHeadSelfAttenti (None, 100, 1024)    0           Encoder-20-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-21-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-21-MultiHeadSelfAttenti (None, 100, 1024)    2048        Encoder-21-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-21-FeedForward (FeedFor (None, 100, 1024)    8393728     Encoder-21-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-21-FeedForward-Dropout  (None, 100, 1024)    0           Encoder-21-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-21-FeedForward-Add (Add (None, 100, 1024)    0           Encoder-21-MultiHeadSelfAttention\n",
      "                                                                 Encoder-21-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-21-FeedForward-Norm (La (None, 100, 1024)    2048        Encoder-21-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-22-MultiHeadSelfAttenti (None, 100, 1024)    4198400     Encoder-21-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-22-MultiHeadSelfAttenti (None, 100, 1024)    0           Encoder-22-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-22-MultiHeadSelfAttenti (None, 100, 1024)    0           Encoder-21-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-22-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-22-MultiHeadSelfAttenti (None, 100, 1024)    2048        Encoder-22-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-22-FeedForward (FeedFor (None, 100, 1024)    8393728     Encoder-22-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-22-FeedForward-Dropout  (None, 100, 1024)    0           Encoder-22-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-22-FeedForward-Add (Add (None, 100, 1024)    0           Encoder-22-MultiHeadSelfAttention\n",
      "                                                                 Encoder-22-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-22-FeedForward-Norm (La (None, 100, 1024)    2048        Encoder-22-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-23-MultiHeadSelfAttenti (None, 100, 1024)    4198400     Encoder-22-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-23-MultiHeadSelfAttenti (None, 100, 1024)    0           Encoder-23-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-23-MultiHeadSelfAttenti (None, 100, 1024)    0           Encoder-22-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-23-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-23-MultiHeadSelfAttenti (None, 100, 1024)    2048        Encoder-23-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-23-FeedForward (FeedFor (None, 100, 1024)    8393728     Encoder-23-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-23-FeedForward-Dropout  (None, 100, 1024)    0           Encoder-23-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-23-FeedForward-Add (Add (None, 100, 1024)    0           Encoder-23-MultiHeadSelfAttention\n",
      "                                                                 Encoder-23-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-23-FeedForward-Norm (La (None, 100, 1024)    2048        Encoder-23-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-24-MultiHeadSelfAttenti (None, 100, 1024)    4198400     Encoder-23-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-24-MultiHeadSelfAttenti (None, 100, 1024)    0           Encoder-24-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-24-MultiHeadSelfAttenti (None, 100, 1024)    0           Encoder-23-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-24-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-24-MultiHeadSelfAttenti (None, 100, 1024)    2048        Encoder-24-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-24-FeedForward (FeedFor (None, 100, 1024)    8393728     Encoder-24-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-24-FeedForward-Dropout  (None, 100, 1024)    0           Encoder-24-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-24-FeedForward-Add (Add (None, 100, 1024)    0           Encoder-24-MultiHeadSelfAttention\n",
      "                                                                 Encoder-24-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-24-FeedForward-Norm (La (None, 100, 1024)    2048        Encoder-24-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Output (Concatenate)    (None, 100, 4096)    0           Encoder-21-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-22-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-23-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-24-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "non_masking_layer (NonMaskingLa (None, 100, 4096)    0           Encoder-Output[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_blstm (Bidirectional)     (None, 100, 256)     4327424     non_masking_layer[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "layer_dropout (Dropout)         (None, 100, 256)     0           layer_blstm[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "layer_time_distributed (TimeDis (None, 100, 3)       771         layer_dropout[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 100, 3)       0           layer_time_distributed[0][0]     \n",
      "==================================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 336,435,971\n",
      "Trainable params: 4,328,195\n",
      "Non-trainable params: 332,107,776\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/30\n",
      "313/314 [============================>.] - ETA: 1s - loss: 0.0593 - acc: 0.9734Epoch 1/30\n",
      "314/314 [==============================] - 446s 1s/step - loss: 0.0592 - acc: 0.9734 - val_loss: 0.0456 - val_acc: 0.9766\n",
      "Epoch 2/30\n",
      "313/314 [============================>.] - ETA: 1s - loss: 0.0410 - acc: 0.9803Epoch 1/30\n",
      "314/314 [==============================] - 437s 1s/step - loss: 0.0410 - acc: 0.9803 - val_loss: 0.0424 - val_acc: 0.9787\n",
      "Epoch 3/30\n",
      "313/314 [============================>.] - ETA: 1s - loss: 0.0383 - acc: 0.9815Epoch 1/30\n",
      "314/314 [==============================] - 439s 1s/step - loss: 0.0383 - acc: 0.9815 - val_loss: 0.0400 - val_acc: 0.9797\n",
      "Epoch 4/30\n",
      "313/314 [============================>.] - ETA: 1s - loss: 0.0365 - acc: 0.9824Epoch 1/30\n",
      "314/314 [==============================] - 438s 1s/step - loss: 0.0365 - acc: 0.9824 - val_loss: 0.0396 - val_acc: 0.9800\n",
      "Epoch 5/30\n",
      "313/314 [============================>.] - ETA: 1s - loss: 0.0353 - acc: 0.9831Epoch 1/30\n",
      "314/314 [==============================] - 438s 1s/step - loss: 0.0353 - acc: 0.9831 - val_loss: 0.0401 - val_acc: 0.9803\n",
      "Epoch 6/30\n",
      "313/314 [============================>.] - ETA: 1s - loss: 0.0343 - acc: 0.9834Epoch 1/30\n",
      "314/314 [==============================] - 453s 1s/step - loss: 0.0344 - acc: 0.9834 - val_loss: 0.0410 - val_acc: 0.9793\n",
      "Epoch 7/30\n",
      "313/314 [============================>.] - ETA: 1s - loss: 0.0334 - acc: 0.9839Epoch 1/30\n",
      "314/314 [==============================] - 440s 1s/step - loss: 0.0334 - acc: 0.9839 - val_loss: 0.0390 - val_acc: 0.9804\n",
      "Epoch 8/30\n",
      "313/314 [============================>.] - ETA: 1s - loss: 0.0324 - acc: 0.9844Epoch 1/30\n",
      "314/314 [==============================] - 440s 1s/step - loss: 0.0324 - acc: 0.9844 - val_loss: 0.0406 - val_acc: 0.9796\n",
      "Epoch 9/30\n",
      "313/314 [============================>.] - ETA: 1s - loss: 0.0319 - acc: 0.9847Epoch 1/30\n",
      "314/314 [==============================] - 437s 1s/step - loss: 0.0319 - acc: 0.9847 - val_loss: 0.0407 - val_acc: 0.9798\n",
      "Epoch 10/30\n",
      "313/314 [============================>.] - ETA: 1s - loss: 0.0313 - acc: 0.9851Epoch 1/30\n",
      "314/314 [==============================] - 438s 1s/step - loss: 0.0313 - acc: 0.9851 - val_loss: 0.0411 - val_acc: 0.9795\n",
      "Epoch 11/30\n",
      "313/314 [============================>.] - ETA: 1s - loss: 0.0306 - acc: 0.9854Epoch 1/30\n",
      "314/314 [==============================] - 437s 1s/step - loss: 0.0306 - acc: 0.9854 - val_loss: 0.0404 - val_acc: 0.9803\n",
      "Epoch 12/30\n",
      "313/314 [============================>.] - ETA: 1s - loss: 0.0299 - acc: 0.9858Epoch 1/30\n",
      "314/314 [==============================] - 437s 1s/step - loss: 0.0299 - acc: 0.9858 - val_loss: 0.0403 - val_acc: 0.9805\n",
      "Epoch 13/30\n",
      "313/314 [============================>.] - ETA: 1s - loss: 0.0295 - acc: 0.9859Epoch 1/30\n",
      "314/314 [==============================] - 437s 1s/step - loss: 0.0295 - acc: 0.9859 - val_loss: 0.0416 - val_acc: 0.9795\n",
      "Epoch 14/30\n",
      "313/314 [============================>.] - ETA: 1s - loss: 0.0290 - acc: 0.9862Epoch 1/30\n",
      "314/314 [==============================] - 438s 1s/step - loss: 0.0290 - acc: 0.9862 - val_loss: 0.0405 - val_acc: 0.9803\n",
      "Epoch 15/30\n",
      "313/314 [============================>.] - ETA: 1s - loss: 0.0284 - acc: 0.9866Epoch 1/30\n",
      "314/314 [==============================] - 437s 1s/step - loss: 0.0284 - acc: 0.9866 - val_loss: 0.0402 - val_acc: 0.9804\n",
      "Epoch 16/30\n",
      "313/314 [============================>.] - ETA: 1s - loss: 0.0280 - acc: 0.9868Epoch 1/30\n",
      "314/314 [==============================] - 437s 1s/step - loss: 0.0280 - acc: 0.9868 - val_loss: 0.0417 - val_acc: 0.9798\n",
      "Epoch 17/30\n",
      "313/314 [============================>.] - ETA: 1s - loss: 0.0276 - acc: 0.9870Epoch 1/30\n",
      "314/314 [==============================] - 437s 1s/step - loss: 0.0276 - acc: 0.9870 - val_loss: 0.0431 - val_acc: 0.9792\n",
      "Epoch 18/30\n",
      "313/314 [============================>.] - ETA: 1s - loss: 0.0272 - acc: 0.9872Epoch 1/30\n",
      "314/314 [==============================] - 438s 1s/step - loss: 0.0272 - acc: 0.9872 - val_loss: 0.0422 - val_acc: 0.9800\n",
      "Epoch 19/30\n",
      "313/314 [============================>.] - ETA: 1s - loss: 0.0267 - acc: 0.9874Epoch 1/30\n",
      "314/314 [==============================] - 437s 1s/step - loss: 0.0267 - acc: 0.9874 - val_loss: 0.0416 - val_acc: 0.9799\n",
      "Epoch 20/30\n",
      "313/314 [============================>.] - ETA: 1s - loss: 0.0263 - acc: 0.9877Epoch 1/30\n",
      "314/314 [==============================] - 438s 1s/step - loss: 0.0263 - acc: 0.9877 - val_loss: 0.0422 - val_acc: 0.9802\n",
      "Epoch 21/30\n",
      "313/314 [============================>.] - ETA: 1s - loss: 0.0258 - acc: 0.9879Epoch 1/30\n",
      "314/314 [==============================] - 438s 1s/step - loss: 0.0258 - acc: 0.9879 - val_loss: 0.0441 - val_acc: 0.9795\n",
      "Epoch 22/30\n",
      "313/314 [============================>.] - ETA: 1s - loss: 0.0254 - acc: 0.9881Epoch 1/30\n",
      "314/314 [==============================] - 438s 1s/step - loss: 0.0254 - acc: 0.9881 - val_loss: 0.0434 - val_acc: 0.9802\n",
      "Epoch 23/30\n",
      "313/314 [============================>.] - ETA: 1s - loss: 0.0252 - acc: 0.9882Epoch 1/30\n",
      "314/314 [==============================] - 437s 1s/step - loss: 0.0252 - acc: 0.9882 - val_loss: 0.0431 - val_acc: 0.9801\n",
      "Epoch 24/30\n",
      "313/314 [============================>.] - ETA: 1s - loss: 0.0248 - acc: 0.9885Epoch 1/30\n",
      "314/314 [==============================] - 437s 1s/step - loss: 0.0248 - acc: 0.9885 - val_loss: 0.0432 - val_acc: 0.9805\n",
      "Epoch 25/30\n",
      "313/314 [============================>.] - ETA: 1s - loss: 0.0245 - acc: 0.9885Epoch 1/30\n",
      "314/314 [==============================] - 437s 1s/step - loss: 0.0245 - acc: 0.9885 - val_loss: 0.0439 - val_acc: 0.9800\n",
      "Epoch 26/30\n",
      "313/314 [============================>.] - ETA: 1s - loss: 0.0242 - acc: 0.9888Epoch 1/30\n",
      "314/314 [==============================] - 437s 1s/step - loss: 0.0242 - acc: 0.9888 - val_loss: 0.0461 - val_acc: 0.9794\n",
      "Epoch 27/30\n",
      "313/314 [============================>.] - ETA: 1s - loss: 0.0239 - acc: 0.9889Epoch 1/30\n",
      "314/314 [==============================] - 438s 1s/step - loss: 0.0240 - acc: 0.9889 - val_loss: 0.0455 - val_acc: 0.9798\n",
      "Epoch 28/30\n",
      "313/314 [============================>.] - ETA: 1s - loss: 0.0235 - acc: 0.9892Epoch 1/30\n",
      "314/314 [==============================] - 437s 1s/step - loss: 0.0235 - acc: 0.9892 - val_loss: 0.0445 - val_acc: 0.9802\n",
      "Epoch 29/30\n",
      "313/314 [============================>.] - ETA: 1s - loss: 0.0231 - acc: 0.9894Epoch 1/30\n",
      "314/314 [==============================] - 437s 1s/step - loss: 0.0231 - acc: 0.9894 - val_loss: 0.0448 - val_acc: 0.9802\n",
      "Epoch 30/30\n",
      "313/314 [============================>.] - ETA: 1s - loss: 0.0229 - acc: 0.9895Epoch 1/30\n",
      "314/314 [==============================] - 437s 1s/step - loss: 0.0229 - acc: 0.9895 - val_loss: 0.0439 - val_acc: 0.9802\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d124b89940>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BiLSTM_Model(bert_embed)\n",
    "#valid_x, valid_y = trainx[:250], trainy[:250]\n",
    "model.fit(store_data_trainx, store_data_trainy, store_data_devx, store_data_devy,epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           precision    recall  f1-score   support\n",
      "\n",
      "        B     0.7072    0.7339    0.7203     31752\n",
      "\n",
      "micro avg     0.7072    0.7339    0.7203     31752\n",
      "macro avg     0.7072    0.7339    0.7203     31752\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'           precision    recall  f1-score   support\\n\\n        B     0.7072    0.7339    0.7203     31752\\n\\nmicro avg     0.7072    0.7339    0.7203     31752\\nmacro avg     0.7072    0.7339    0.7203     31752\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 验证模型，此方法将打印出详细的验证报告  30\n",
    "model.evaluate(store_data_testx, store_data_testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           precision    recall  f1-score   support\n",
      "\n",
      "        B     0.7152    0.7262    0.7207     31752\n",
      "\n",
      "micro avg     0.7152    0.7262    0.7207     31752\n",
      "macro avg     0.7152    0.7262    0.7207     31752\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'           precision    recall  f1-score   support\\n\\n        B     0.7152    0.7262    0.7207     31752\\n\\nmicro avg     0.7152    0.7262    0.7207     31752\\nmacro avg     0.7152    0.7262    0.7207     31752\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 验证模型，此方法将打印出详细的验证报告\n",
    "model.evaluate(store_data_testx, store_data_testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           precision    recall  f1-score   support\n",
      "\n",
      "        B     0.7316    0.6727    0.7009     31752\n",
      "\n",
      "micro avg     0.7316    0.6727    0.7009     31752\n",
      "macro avg     0.7316    0.6727    0.7009     31752\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'           precision    recall  f1-score   support\\n\\n        B     0.7316    0.6727    0.7009     31752\\n\\nmicro avg     0.7316    0.6727    0.7009     31752\\nmacro avg     0.7316    0.6727    0.7009     31752\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 验证模型，此方法将打印出详细的验证报告     50\n",
    "model.evaluate(store_data_testx, store_data_testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kashgari.embeddings import BERTEmbedding\n",
    "from kashgari.tasks.labeling import BiLSTM_CRF_Model\n",
    "#bert_embedding = BERTEmbedding('wwm_cased_L-24_H-1024_A-16', sequence_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:seq_len: 100\n"
     ]
    }
   ],
   "source": [
    "bert_embed = BERTEmbedding('wwm_cased_L-24_H-1024_A-16',task=kashgari.LABELING,sequence_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Sequence length will auto set at 95% of sequence length\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 50)]              0         \n",
      "_________________________________________________________________\n",
      "layer_embedding (Embedding)  (None, 50, 100)           1101800   \n",
      "_________________________________________________________________\n",
      "layer_blstm (Bidirectional)  (None, 50, 256)           235520    \n",
      "_________________________________________________________________\n",
      "layer_dropout (Dropout)      (None, 50, 256)           0         \n",
      "_________________________________________________________________\n",
      "layer_time_distributed (Time (None, 50, 3)             771       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 50, 3)             0         \n",
      "=================================================================\n",
      "Total params: 1,338,091\n",
      "Trainable params: 1,338,091\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "310/314 [============================>.] - ETA: 0s - loss: 0.1368 - acc: 0.9504Epoch 1/10\n",
      "314/314 [==============================] - 10s 31ms/step - loss: 0.1356 - acc: 0.9508 - val_loss: 0.0825 - val_acc: 0.9613\n",
      "Epoch 2/10\n",
      "310/314 [============================>.] - ETA: 0s - loss: 0.0375 - acc: 0.9864Epoch 1/10\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0375 - acc: 0.9864 - val_loss: 0.0947 - val_acc: 0.9614\n",
      "Epoch 3/10\n",
      "313/314 [============================>.] - ETA: 0s - loss: 0.0309 - acc: 0.9886Epoch 1/10\n",
      "314/314 [==============================] - 3s 10ms/step - loss: 0.0308 - acc: 0.9887 - val_loss: 0.0827 - val_acc: 0.9663\n",
      "Epoch 4/10\n",
      "311/314 [============================>.] - ETA: 0s - loss: 0.0250 - acc: 0.9908Epoch 1/10\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0250 - acc: 0.9908 - val_loss: 0.0788 - val_acc: 0.9682\n",
      "Epoch 5/10\n",
      "311/314 [============================>.] - ETA: 0s - loss: 0.0203 - acc: 0.9924Epoch 1/10\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0204 - acc: 0.9924 - val_loss: 0.0896 - val_acc: 0.9673\n",
      "Epoch 6/10\n",
      "310/314 [============================>.] - ETA: 0s - loss: 0.0172 - acc: 0.9936Epoch 1/10\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0172 - acc: 0.9937 - val_loss: 0.0964 - val_acc: 0.9668\n",
      "Epoch 7/10\n",
      "312/314 [============================>.] - ETA: 0s - loss: 0.0150 - acc: 0.9944Epoch 1/10\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0150 - acc: 0.9944 - val_loss: 0.1124 - val_acc: 0.9661\n",
      "Epoch 8/10\n",
      "313/314 [============================>.] - ETA: 0s - loss: 0.0131 - acc: 0.9952Epoch 1/10\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0131 - acc: 0.9952 - val_loss: 0.1151 - val_acc: 0.9678\n",
      "Epoch 9/10\n",
      "312/314 [============================>.] - ETA: 0s - loss: 0.0112 - acc: 0.9959Epoch 1/10\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0112 - acc: 0.9959 - val_loss: 0.1186 - val_acc: 0.9673\n",
      "Epoch 10/10\n",
      "310/314 [============================>.] - ETA: 0s - loss: 0.0095 - acc: 0.9965Epoch 1/10\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0095 - acc: 0.9965 - val_loss: 0.1215 - val_acc: 0.9676\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dd5fbca828>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BiLSTM_Model()\n",
    "#valid_x, valid_y = trainx[:250], trainy[:250]\n",
    "model.fit(store_data_trainx, store_data_trainy, store_data_devx, store_data_devy,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           precision    recall  f1-score   support\n",
      "\n",
      "        B     0.7911    0.7561    0.7732     31293\n",
      "\n",
      "micro avg     0.7910    0.7561    0.7731     31293\n",
      "macro avg     0.7911    0.7561    0.7732     31293\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'           precision    recall  f1-score   support\\n\\n        B     0.7911    0.7561    0.7732     31293\\n\\nmicro avg     0.7910    0.7561    0.7731     31293\\nmacro avg     0.7911    0.7561    0.7732     31293\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 验证模型，此方法将打印出详细的验证报告\n",
    "model.evaluate(store_data_testx, store_data_testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## after lemma word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Sequence length will auto set at 95% of sequence length\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 50)]              0         \n",
      "_________________________________________________________________\n",
      "layer_embedding (Embedding)  (None, 50, 100)           1034900   \n",
      "_________________________________________________________________\n",
      "layer_blstm (Bidirectional)  (None, 50, 256)           235520    \n",
      "_________________________________________________________________\n",
      "layer_dropout (Dropout)      (None, 50, 256)           0         \n",
      "_________________________________________________________________\n",
      "layer_time_distributed (Time (None, 50, 3)             771       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 50, 3)             0         \n",
      "=================================================================\n",
      "Total params: 1,271,191\n",
      "Trainable params: 1,271,191\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "312/314 [============================>.] - ETA: 0s - loss: 0.1355 - acc: 0.9476Epoch 1/10\n",
      "314/314 [==============================] - 4s 12ms/step - loss: 0.1351 - acc: 0.9477 - val_loss: 0.0812 - val_acc: 0.9622\n",
      "Epoch 2/10\n",
      "309/314 [============================>.] - ETA: 0s - loss: 0.0374 - acc: 0.9865Epoch 1/10\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0373 - acc: 0.9865 - val_loss: 0.0741 - val_acc: 0.9651\n",
      "Epoch 3/10\n",
      "313/314 [============================>.] - ETA: 0s - loss: 0.0313 - acc: 0.9883Epoch 1/10\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0313 - acc: 0.9883 - val_loss: 0.0834 - val_acc: 0.9660\n",
      "Epoch 4/10\n",
      "310/314 [============================>.] - ETA: 0s - loss: 0.0255 - acc: 0.9904Epoch 1/10\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0255 - acc: 0.9904 - val_loss: 0.0812 - val_acc: 0.9676\n",
      "Epoch 5/10\n",
      "309/314 [============================>.] - ETA: 0s - loss: 0.0208 - acc: 0.9922Epoch 1/10\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0209 - acc: 0.9922 - val_loss: 0.0934 - val_acc: 0.9667\n",
      "Epoch 6/10\n",
      "307/314 [============================>.] - ETA: 0s - loss: 0.0175 - acc: 0.9935Epoch 1/10\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0177 - acc: 0.9935 - val_loss: 0.0907 - val_acc: 0.9687\n",
      "Epoch 7/10\n",
      "312/314 [============================>.] - ETA: 0s - loss: 0.0155 - acc: 0.9943Epoch 1/10\n",
      "314/314 [==============================] - 3s 10ms/step - loss: 0.0155 - acc: 0.9943 - val_loss: 0.0961 - val_acc: 0.9689\n",
      "Epoch 8/10\n",
      "312/314 [============================>.] - ETA: 0s - loss: 0.0138 - acc: 0.9949Epoch 1/10\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0138 - acc: 0.9949 - val_loss: 0.1216 - val_acc: 0.9669\n",
      "Epoch 9/10\n",
      "307/314 [============================>.] - ETA: 0s - loss: 0.0124 - acc: 0.9955Epoch 1/10\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0124 - acc: 0.9954 - val_loss: 0.1018 - val_acc: 0.9683\n",
      "Epoch 10/10\n",
      "309/314 [============================>.] - ETA: 0s - loss: 0.0104 - acc: 0.9962Epoch 1/10\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0105 - acc: 0.9962 - val_loss: 0.1192 - val_acc: 0.9671\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1df258c1978>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BiLSTM_Model()\n",
    "#valid_x, valid_y = trainx[:250], trainy[:250]\n",
    "model.fit(store_data_trainx, store_data_trainy, store_data_devx, store_data_devy,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           precision    recall  f1-score   support\n",
      "\n",
      "        B     0.8009    0.7189    0.7577     31293\n",
      "\n",
      "micro avg     0.8007    0.7189    0.7576     31293\n",
      "macro avg     0.8009    0.7189    0.7577     31293\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'           precision    recall  f1-score   support\\n\\n        B     0.8009    0.7189    0.7577     31293\\n\\nmicro avg     0.8007    0.7189    0.7576     31293\\nmacro avg     0.8009    0.7189    0.7577     31293\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 验证模型，此方法将打印出详细的验证报告\n",
    "model.evaluate(store_data_testx, store_data_testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_serving.client import BertClient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
